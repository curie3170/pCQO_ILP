{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6964,"status":"ok","timestamp":1708347810905,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"zNeSMnG4FQf0","outputId":"2cc9cfcf-f331-4718-a4bc-99d8a27c764f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (3.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install networkx"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":258,"status":"ok","timestamp":1708358948157,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"JfWS5N-mFczw"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import networkx as nx\n","import numpy as np\n","import torch.optim as optim\n","from itertools import combinations\n","import pickle\n","import cvxpy as cp"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3011,"status":"ok","timestamp":1708358998892,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"abNNgJqnFfFU","outputId":"a485c8af-077c-4f26-d769-7fbcb0a8e51b"},"outputs":[{"name":"stdout","output_type":"stream","text":["50 613\n"]}],"source":["# Define a graph\n","# n = 50  # number of nodes\n","# m = 613  # number of edges\n","# G = nx.gnm_random_graph(n, m, seed = 0)\n","\n","import pickle\n","\n","#G = nx.gnm_random_graph(n, m, seed = 4) # This graph has a MIS of 5, and it is hard to find!!! They are {0, 2, 9, 10, 11} and {0, 2, 8, 9, 11}\n","# Create a G(n, m) random graph\n","def destringizer(value):\n","    try:\n","        # Try to convert the string to an integer\n","        return int(value)\n","    except ValueError:\n","        try:\n","            # Try to convert the string to a float\n","            return float(value)\n","        except ValueError:\n","            # If conversion fails, return the original string\n","            return value\n","\n","# Load the .gml graph using nx.read_gml and provide the destringizer function\n","#G = nx.read_gml(\"GNM_n50_m613_seed9.gml\", destringizer=destringizer)\n","\n","with open(\"./graphs/test/GNM_50_613_2.gpickle\", \"rb\") as f:\n","    G = pickle.load(f)\n","    \n","\n","#G = nx.read_gpickle(\"/content/ER_700_800_0.15_0.gpickle\")\n","\n","# file_path = \"/content/uf20-04.gpickle\"\n","\n","# with open(file_path, 'rb') as f:\n","#     G = pickle.load(f)\n","\n","n = len(G.nodes)\n","m = len(G.edges)\n","#print(G.edges)\n","complement_G = nx.complement(G)\n","\n","print(n,m)\n","\n","\n","\n","### Visualize the graph\n","#nx.draw(G, with_labels=True, font_weight='bold')"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"xat9Q8ehePqB"},"outputs":[],"source":["6\n","import numpy as np\n","import networkx as nx\n","from mosek.fusion import Model, Domain, ObjectiveSense, Matrix, Expr\n","# Get the adjacency matrix\n","A = np.array(nx.adjacency_matrix(G).todense())\n","# Get the number of nodes\n","n = len(G.nodes)\n","matrix_of_ones = np.ones((n, n))\n","# Create a MOSEK model\n","with Model(\"SDP_init\") as m:\n","    # Create the matrix variable X\n","    X = m.variable('X', [n, n], Domain.inPSDCone())\n","    #ones_mat = mosek.fusion.Expression.constant(1.0, n, n)\n","    objective_expr = Expr.dot(matrix_of_ones, X)\n","    # Set the objective: maximize the trace of X\n","    m.objective('obj', ObjectiveSense.Maximize, objective_expr)\n","    # Add constraints: trace(X) == 1 and X_{i,j} == 0 for all {i, j} in E\n","    m.constraint('tr', Expr.sum(X.diag()), Domain.equalsTo(1.0))\n","    for edge in G.edges:\n","        i, j = edge\n","        m.constraint(f'con_{i}_{j}', X.index(i, j), Domain.equalsTo(0.0))\n","        m.constraint(f'con_{j}_{i}', X.index(j, i), Domain.equalsTo(0.0))\n","    # Solve the problem\n","    m.solve()\n","    # Get the solution\n","    \n","    X_solution = X.level()\n","    X_solution = np.array(X_solution)\n","    X_solution = X_solution.reshape(n,n)\n","    #X_solution = m.getPrimalSolution()\n","\n","# Extract the solution\n","X_SDP_solution = X_solution"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1708354496683,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"hXJnlpz9fBDj","outputId":"cd2ae160-78a6-4811-ad9c-521a39e42641"},"outputs":[{"name":"stdout","output_type":"stream","text":["50\n","[0.32309889 0.1977664  0.54126133 0.42705276 0.21979998 0.53489048\n"," 0.00790294 0.52872923 0.11137632 0.02165114]\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_42697/129330673.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  W_SDP_uv_tensor = torch.tensor(W_SDP_uv, dtype=torch.float32)\n"]}],"source":["######### Coding up W_SDP_uv for (u,v) not in E, vector s_SDP_v (for the first term from the diagonal of X_SDP), and X_SDP_init:\n","\n","## Coding W_SDP_uv:\n","W_SDP_uv = torch.zeros(n,n)\n","\n","# create a dictionary of key = edge (u,v) in G' and value is equation to X(u,v)\n","G_hat_edges_strength_dict = {}\n","\n","for v in range(n):\n","  for u in range(n):\n","    if (v,u) not in G.edges() and u != v:\n","      G_hat_edges_strength_dict[(v,u)] =  X_SDP_solution[v,u]\n","\n","# Normalize\n","values_array = np.array(list(G_hat_edges_strength_dict.values()))\n","normalized_values_MINMAX = (values_array - np.min(values_array)) / (np.max(values_array) - np.min(values_array))\n","G_hat_edges_strength_dict_normalized_MINMAX = {key: normalized_values_MINMAX[i] for i, key in enumerate(G_hat_edges_strength_dict)} ######## USE THIS\n","\n","# Assign to W_SDP_uv\n","for v in range(n):\n","  for u in range(n):\n","    if (v,u) not in G.edges() and v != u:\n","      W_SDP_uv[v,u] = G_hat_edges_strength_dict_normalized_MINMAX[(v,u)]\n","\n","# print(W_SDP_uv[1,88])\n","# print(G_hat_edges_strength_dict_normalized_MINMAX[(1,88)])\n","# print(X_SDP_solution[1,88])\n","\n","## Coding s_SDP_v and X_SDP_init:\n","\n","sol_diag = np.diag(X_SDP_solution)\n","s_SDP_v = sol_diag / np.max(sol_diag)\n","X_SDP_init = (sol_diag - np.min(sol_diag)) / (np.max(sol_diag) - np.min(sol_diag))\n","print(len(s_SDP_v))\n","print(X_SDP_init[0:10])\n","\n","### Converting to torch tensors: Convert s_SDP_v and W_SDP_uv to torch tensors\n","s_SDP_v_tensor = torch.tensor(s_SDP_v, dtype=torch.float32)\n","X_SDP_init_tensor = torch.tensor(X_SDP_init, dtype=torch.float32)\n","W_SDP_uv_tensor = torch.tensor(W_SDP_uv, dtype=torch.float32)\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1708354498666,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"l6BQRg2ZFkEo"},"outputs":[],"source":["# ### Obtain the A_G matrix\n","\n","# adjacency_matrix = nx.adjacency_matrix(G)\n","# adjacency_matrix_dense = adjacency_matrix.todense()\n","# adjacency_matrix_tensor = torch.tensor(adjacency_matrix_dense, dtype=torch.float32)\n","\n","# ### Obtain the A_G_hat matrix\n","\n","# adjacency_matrix_comp = nx.adjacency_matrix(complement_G)\n","# adjacency_matrix_dense_comp = adjacency_matrix_comp.todense()\n","# adjacency_matrix_tensor_comp = torch.tensor(adjacency_matrix_dense_comp, dtype=torch.float32)\n","\n","# def loss_function(adjacency_matrix_tensor,adjacency_matrix_tensor_comp, Matrix_X, gamma, beta):\n","#     ## without edges of the comp graph:\n","#     #loss = -Matrix_X.sum() + (gamma/2) * (Matrix_X.T @ (adjacency_matrix_tensor) @ Matrix_X)\n","\n","#     ## with edges of the comp graph:\n","#     loss = -Matrix_X.sum() + (gamma/2) * (Matrix_X.T @ (adjacency_matrix_tensor) @ Matrix_X) - (beta/2) * (Matrix_X.T @ (adjacency_matrix_tensor_comp) @ Matrix_X)\n","#     return loss\n","\n","# # # test function:\n","# # Matrix_X = torch.rand((len(G.nodes),1), requires_grad=True)\n","# # print(\"testing the function: \", loss_function(adjacency_matrix_tensor,adjacency_matrix_tensor_comp, Matrix_X, gamma=5, beta = 1))\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1708354500498,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"OEzShtoFjJjz"},"outputs":[],"source":["########## DEFINING THE SDP ENCODED LOSS:\n","\n","### Obtain the A_G matrix\n","\n","adjacency_matrix = nx.adjacency_matrix(G)\n","adjacency_matrix_dense = adjacency_matrix.todense()\n","adjacency_matrix_tensor = torch.tensor(adjacency_matrix_dense, dtype=torch.float32)\n","\n","### Obtain the A_G_hat matrix\n","\n","adjacency_matrix_comp = nx.adjacency_matrix(complement_G)\n","adjacency_matrix_dense_comp = adjacency_matrix_comp.todense()\n","adjacency_matrix_tensor_comp = torch.tensor(adjacency_matrix_dense_comp, dtype=torch.float32)\n","\n","\n","\n","def loss_function_with_SDP(adjacency_matrix_tensor,adjacency_matrix_tensor_comp, Matrix_X, s_SDP_v_tensor, W_SDP_uv_tensor, gamma, beta):\n","    ## without edges of the comp graph:\n","    #loss = -Matrix_X.sum() + (gamma/2) * (Matrix_X.T @ (adjacency_matrix_tensor) @ Matrix_X)\n","    beta = 1\n","\n","    ## with edges of the comp graph:\n","    #loss = -Matrix_X.sum() + (gamma/2) * (Matrix_X.T @ (adjacency_matrix_tensor) @ Matrix_X) - (beta/2) * (Matrix_X.T @ (adjacency_matrix_tensor_comp) @ Matrix_X)\n","    loss = -(Matrix_X.T @ s_SDP_v_tensor) + (gamma/2) * (Matrix_X.T @ (adjacency_matrix_tensor) @ Matrix_X) - (beta/2) * (Matrix_X.T @ (adjacency_matrix_tensor_comp*W_SDP_uv_tensor) @ Matrix_X)\n","   \n","    return loss\n","\n","# # test function:\n","# Matrix_X = torch.rand((len(G.nodes),1), requires_grad=True)\n","# print(\"testing the function: \", loss_function(adjacency_matrix_tensor,adjacency_matrix_tensor_comp, Matrix_X, gamma=5, beta = 1))"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1708354502695,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"ZVZIMAIlgljg","outputId":"8f105ddc-a8ec-4a64-d589-f3ea3327e76c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of positive values with: 23\n","Number of negative values with: 27\n","Number of positive values without: 23\n","Number of negative values without: 27\n","tensor([1123.5985,  266.6604,  246.7255,  227.6500,  211.4142,  204.9311,\n","        -291.5586, -281.4910, -267.3660, -247.1451, -241.7281,  184.6110,\n","         172.2946,  159.4749,  154.2748, -227.6759,  133.4322,  125.1151,\n","         113.1092,  110.2599, -212.4972, -206.4571,   94.0410, -194.7748,\n","        -183.0060,   81.5737, -169.8249, -161.1875, -155.0575, -146.8756,\n","          72.8810,   63.1747,   49.3723,   41.5685,   31.8052,   17.8051,\n","           3.5495,  -10.0580,  -14.0165,  -16.7843,  -36.2908,  -55.6776,\n","        -126.2593,  -69.9073, -111.5998,  -82.0686,  -85.9059, -100.3713,\n","         -98.0170,  -95.7223])\n"]}],"source":["# Constructing the constant Hessian and looking at the eigen values: This depends on the connectivity of graph... The more edges, the worst, which we already know\n","gamma = 90 # I select this from the best solution from ReduMIS: Double check the bounds with Rongrong\n","beta = 1\n","Hessian = torch.zeros(n, n)\n","complement_G = nx.complement(G)\n","\n","Hessian_with_third = (gamma/2)*adjacency_matrix_tensor - (beta/2)*adjacency_matrix_tensor_comp\n","Hessain_without    = (gamma/2)*adjacency_matrix_tensor\n","\n","# Compute eigenvalues\n","eigenvalues_with, _ = torch.linalg.eig(Hessian_with_third)\n","\n","# Extract the real part of the eigenvalues\n","real_eigenvalues_with = eigenvalues_with.real\n","\n","\n","# Compute eigenvalues\n","eigenvalues_without, _ = torch.linalg.eig(Hessain_without)\n","\n","# Extract the real part of the eigenvalues\n","real_eigenvalues_without = eigenvalues_without.real\n","\n","#print(\"Eigenvalues without:\", real_eigenvalues_without)\n","\n","# Count positive values\n","positive_count_with = torch.sum(real_eigenvalues_with > 0).item()\n","\n","# Count negative values\n","negative_count_with = torch.sum(real_eigenvalues_with < 0).item()\n","\n","print(\"Number of positive values with:\", positive_count_with)\n","print(\"Number of negative values with:\", negative_count_with)\n","\n","# Count positive values\n","positive_count_without = torch.sum(real_eigenvalues_without > 0).item()\n","\n","# Count negative values\n","negative_count_without = torch.sum(real_eigenvalues_without < 0).item()\n","\n","print(\"Number of positive values without:\", positive_count_without)\n","print(\"Number of negative values without:\", negative_count_without)\n","\n","print(real_eigenvalues_without)\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1708354505387,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"Y1A36XxzIqVU","outputId":"26f4dbdc-77fc-453c-9dc2-7f1ae8c64697"},"outputs":[{"name":"stdout","output_type":"stream","text":["(False, False)\n","(False, False)\n","(False, False)\n","(False, False)\n","tensor([3.2310e-01, 1.9777e-01, 5.4126e-01, 4.2705e-01, 2.1980e-01, 5.3489e-01,\n","        7.9029e-03, 5.2873e-01, 1.1138e-01, 2.1651e-02, 9.6038e-01, 7.4878e-02,\n","        6.7653e-01, 8.0132e-02, 6.4952e-02, 9.5737e-01, 5.6174e-01, 6.5433e-01,\n","        5.4302e-01, 1.7846e-01, 1.0901e-01, 1.6238e-01, 5.2830e-01, 0.0000e+00,\n","        1.0000e+00, 2.0092e-02, 4.0240e-01, 2.3630e-01, 1.1440e-01, 9.6343e-04,\n","        2.3926e-03, 7.2893e-01, 3.6792e-02, 2.2788e-01, 2.7230e-01, 2.6553e-01,\n","        6.8889e-01, 2.5337e-01, 1.7956e-01, 2.2463e-02, 5.1937e-01, 8.1990e-01,\n","        3.9611e-02, 3.8048e-02, 4.9017e-01, 2.6735e-01, 7.2446e-02, 1.1511e-01,\n","        5.0320e-01, 5.2167e-01])\n"]}],"source":["# This is a function to double check if the MIS we find is a valid IS and/or MIS\n","\n","def MIS_checker(MIS_list, G):\n","  pairs = list(combinations(MIS_list, 2))\n","  IS_CHECKER = True\n","  if len(MIS_list)>1:\n","    for pair in pairs:\n","      if (pair[0], pair[1]) in G.edges or (pair[1], pair[0]) in G.edges:\n","        IS_CHECKER =  False\n","        break\n","  # is it a MIS or IS?\n","  # if MIS_list is an IS:\n","  if IS_CHECKER:\n","    #print(\"Its an IS\")\n","    # obtain a list of all niebouring nodes\n","    list_of_all_Ns_in_MIS_list = []\n","    for node in MIS_list:\n","      list_of_all_Ns_in_MIS_list.append(list(G.neighbors(node)))\n","\n","    flattened_list_of_all_Ns_in_MIS_list = [item for sublist in list_of_all_Ns_in_MIS_list for item in sublist]\n","    #print(flattened_list_of_all_Ns_in_MIS_list)\n","\n","    list_of_nodes_inG_but_not_in_MIStoCHeck = [item for item in list(G.nodes) if item not in MIS_list]\n","\n","    MIS_CHECKER = True\n","    for node in list_of_nodes_inG_but_not_in_MIStoCHeck:\n","      if node not in flattened_list_of_all_Ns_in_MIS_list:\n","        MIS_CHECKER = False\n","        break\n","  else:\n","    IS_CHECKER = False\n","    MIS_CHECKER = False\n","  return IS_CHECKER, MIS_CHECKER\n","\n","# test function: use G = nx.gnm_random_graph(15, 52, seed = 4)\n","print(MIS_checker([0, 1, 2, 3, 4], G))  # Not a valid IS\n","\n","print(MIS_checker([1, 9], G))  # A valid IS\n","\n","print(MIS_checker([0, 2, 9, 10, 11], G))  # A valid MIS\n","\n","print(MIS_checker([0, 2, 9, 10], G))  # A valid IS\n","\n","\n","print(X_SDP_init_tensor)\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1708354508163,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"SqD4m3D59BQL","outputId":"a902bed1-76e2-4181-9a96-8e1a1b62e6d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[800, 1600, 2400, 3200, 4000, 4800, 5600, 6400, 7200, 8000, 8800, 9600, 10400, 11200, 12000, 12800, 13600, 14400, 15200, 16000, 16800, 17600, 18400, 19200, 20000, 20800, 21600, 22400, 23200, 24000, 24800, 25600, 26400, 27200, 28000, 28800, 29600, 30400, 31200, 32000, 32800, 33600, 34400, 35200, 36000, 36800, 37600, 38400, 39200, 40000, 40800, 41600, 42400, 43200, 44000, 44800, 45600, 46400, 47200, 48000, 48800, 49600, 50400, 51200, 52000, 52800, 53600, 54400, 55200, 56000, 56800, 57600, 58400, 59200, 60000, 60800, 61600, 62400, 63200, 64000, 64800, 65600, 66400, 67200, 68000, 68800, 69600, 70400, 71200, 72000, 72800, 73600, 74400, 75200, 76000, 76800, 77600, 78400, 79200, 80000, 80800, 81600, 82400, 83200, 84000, 84800, 85600, 86400, 87200, 88000, 88800, 89600, 90400, 91200, 92000, 92800, 93600, 94400, 95200, 96000, 96800, 97600, 98400, 99200, 100000]\n","tensor([3.2310e-01, 1.9777e-01, 5.4126e-01, 4.2705e-01, 2.1980e-01, 5.3489e-01,\n","        7.9029e-03, 5.2873e-01, 1.1138e-01, 2.1651e-02, 9.6038e-01, 7.4878e-02,\n","        6.7653e-01, 8.0132e-02, 6.4952e-02, 9.5737e-01, 5.6174e-01, 6.5433e-01,\n","        5.4302e-01, 1.7846e-01, 1.0901e-01, 1.6238e-01, 5.2830e-01, 0.0000e+00,\n","        1.0000e+00, 2.0092e-02, 4.0240e-01, 2.3630e-01, 1.1440e-01, 9.6343e-04,\n","        2.3926e-03, 7.2893e-01, 3.6792e-02, 2.2788e-01, 2.7230e-01, 2.6553e-01,\n","        6.8889e-01, 2.5337e-01, 1.7956e-01, 2.2463e-02, 5.1937e-01, 8.1990e-01,\n","        3.9611e-02, 3.8048e-02, 4.9017e-01, 2.6735e-01, 7.2446e-02, 1.1511e-01,\n","        5.0320e-01, 5.2167e-01])\n"]}],"source":["start_value = 800\n","end_value = 100000\n","step = 800\n","\n","Indicies_for_complete_restart = list(range(start_value, end_value + 1, step))\n","\n","print(Indicies_for_complete_restart)\n","\n","print(X_SDP_init_tensor)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":697851,"status":"ok","timestamp":1708357297353,"user":{"displayName":"Ismail Alkhouri","userId":"13482369180561525498"},"user_tz":300},"id":"HqtHy0urIJSD","outputId":"c0ac0a59-eda7-4da3-a45e-d0a6dfcff749"},"outputs":[{"name":"stdout","output_type":"stream","text":["+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.668026924133301 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 200/10000, IS: [31], lr: 0.5, Loss: -0.3208966851234436\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.745237350463867 ++++++++++++ [[12, 16, 24, 31, 40, 41]]\n","Step 400/10000, IS: [10, 12, 16, 18, 24], lr: 0.5, Loss: -0.9087883830070496\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.814572811126709 ++++++++++++ [[5, 10, 12, 16, 18, 24]]\n"]},{"name":"stdout","output_type":"stream","text":["+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.758162260055542 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.7861788272857666 ++++++++++++ [[15, 16, 24, 31, 40, 41]]\n","Step 800/10000, IS: [], lr: 0.5, Loss: -0.3154793381690979\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.836010217666626 ++++++++++++ [[2, 10, 17, 24, 36, 48]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.655810594558716 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 1000/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7679386138916016 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 1200/10000, IS: [], lr: 0.5, Loss: -0.18531905114650726\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.6688425540924072 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 1400/10000, IS: [10, 15, 16, 24, 41], lr: 0.5, Loss: -0.932546854019165\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7511510848999023 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.7660679817199707 ++++++++++++ [[15, 16, 24, 31, 41, 44]]\n","Step 1600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.518700122833252 ++++++++++++ [[1, 10, 15, 16, 18, 24]]\n","Step 1800/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.662362813949585 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 2000/10000, IS: [], lr: 0.5, Loss: -0.37985509634017944\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.796549081802368 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.722931385040283 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 2200/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7360305786132812 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 2400/10000, IS: [], lr: 0.5, Loss: -0.0017051143804565072\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.4906728267669678 ++++++++++++ [[10, 15, 16, 18, 19, 24, 27]]\n","Step 2600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.7080681324005127 ++++++++++++ [[15, 16, 24, 31, 40, 41]]\n","Step 2800/10000, IS: [], lr: 0.5, Loss: -0.11813627928495407\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.787787675857544 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.6731176376342773 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 3000/10000, IS: [], lr: 0.5, Loss: 45.73403549194336\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.754039764404297 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 3200/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.5063705444335938 ++++++++++++ [[1, 10, 15, 16, 18, 24]]\n","Step 3400/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7451343536376953 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 3600/10000, IS: [], lr: 0.5, Loss: -0.08658529072999954\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7508203983306885 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 3800/10000, IS: [10, 24], lr: 0.5, Loss: -0.5656906366348267\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.722669839859009 ++++++++++++ [[10, 15, 17, 24, 40, 41, 48]]\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.731565237045288 ++++++++++++ [[15, 16, 24, 31, 41, 44]]\n","Step 4000/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.786832571029663 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 4200/10000, IS: [24], lr: 0.5, Loss: -0.3092573881149292\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.7540295124053955 ++++++++++++ [[15, 16, 24, 31, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.786283254623413 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 4400/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.4878759384155273 ++++++++++++ [[10, 15, 16, 18, 19, 24, 27]]\n","Step 4600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.793067455291748 ++++++++++++ [[10, 15, 17, 24, 40, 41, 48]]\n","Step 4800/10000, IS: [], lr: 0.5, Loss: -0.14155225455760956\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7195258140563965 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 5000/10000, IS: [10, 24], lr: 0.5, Loss: -0.524845540523529\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7331721782684326 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.711923122406006 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 5200/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.768845319747925 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 5400/10000, IS: [], lr: 0.5, Loss: -0.04140995815396309\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7878682613372803 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 5600/10000, IS: [10, 15, 16, 17, 24], lr: 0.5, Loss: -0.8470852375030518\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.785858631134033 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.760510206222534 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 5800/10000, IS: [], lr: 0.5, Loss: -0.005961687304079533\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7886722087860107 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7892868518829346 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 6000/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.8371775150299072 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 6200/10000, IS: [], lr: 0.5, Loss: -0.10247436165809631\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.5824944972991943 ++++++++++++ [[10, 12, 16, 24, 33, 40, 41]]\n","Step 6400/10000, IS: [], lr: 0.5, Loss: -0.3250175416469574\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.829169988632202 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.685131549835205 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 6600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7840490341186523 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 6800/10000, IS: [], lr: 0.5, Loss: -0.19030608236789703\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.7352685928344727 ++++++++++++ [[15, 16, 24, 31, 40, 41]]\n","Step 7000/10000, IS: [10, 15, 17, 24, 40, 41], lr: 0.5, Loss: -1.093808650970459\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7620718479156494 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.765382766723633 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 7200/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.6685917377471924 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 7400/10000, IS: [], lr: 0.5, Loss: -0.17233328521251678\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.715348958969116 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.748684883117676 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 7600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.8032643795013428 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 7800/10000, IS: [], lr: 0.5, Loss: -0.1504111886024475\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.560567617416382 ++++++++++++ [[1, 10, 15, 16, 18, 24]]\n","Step 8000/10000, IS: [], lr: 0.5, Loss: -0.2746121883392334\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.8161396980285645 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.798553228378296 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 8200/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7282462120056152 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 8400/10000, IS: [], lr: 0.5, Loss: -0.20147670805454254\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.714230537414551 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.814121961593628 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 8600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.73626446723938 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 8800/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7356348037719727 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 9000/10000, IS: [], lr: 0.5, Loss: -0.16158947348594666\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7761518955230713 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7138078212738037 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 9200/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.6988301277160645 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 9400/10000, IS: [36], lr: 0.5, Loss: -0.2687712013721466\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.7098140716552734 ++++++++++++ [[2, 10, 17, 24, 36, 48]]\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7706856727600098 ++++++++++++ [[10, 15, 16, 17, 24, 40, 41]]\n","Step 9600/10000, IS: [], lr: 0.5, Loss: 0.0\n","+++++++++++ A MIS is found with size:  [[[7]]] ++++ BEST so far [7] Dist from Init: = 2.7439353466033936 ++++++++++++ [[2, 5, 10, 12, 18, 24, 36]]\n","Step 9800/10000, IS: [], lr: 0.5, Loss: -0.10539299994707108\n","+++++++++++ A MIS is found with size:  [[[6]]] ++++ BEST so far [7] Dist from Init: = 2.6780898571014404 ++++++++++++ [[0, 2, 10, 17, 24, 36]]\n","Step 10000/10000, IS: [10, 24, 36], lr: 0.5, Loss: -0.7074145674705505\n"]}],"source":["# Optimization loop:\n","# Initialization:\n","torch.manual_seed(115)\n","#Matrix_X = torch.zeros((n), requires_grad=True)\n","#Matrix_X = torch.ones((n), requires_grad=True)\n","#Matrix_X = torch.rand((n), requires_grad=True)\n","\n","lower_bound = 0.01\n","upper_bound = 0.2\n","# Matrix_X = (upper_bound - lower_bound) * torch.rand(n) + lower_bound\n","#Matrix_X = 1.0*torch.ones(n)\n","Matrix_X = X_SDP_init_tensor.clone()\n","Matrix_X.requires_grad_(True)\n","\n","\n","# dict for saving... I am thinking of diversification by looking at previous initializations... Still under investigation\n","dict_of_inits = {}\n","\n","# This is obtained to get a sense of how far are we from the init\n","X_ini  = Matrix_X.data.clone()\n","#gamma = torch.tensor(50.0, requires_grad=True)\n","\n","learning_rate_alpha = 0.5\n","number_of_iterations_T = 10000\n","\n","\n","# Define Optimizer over matrix X\n","#optimizer = optim.Adam([Matrix_X], lr=learning_rate_alpha, weight_decay=10)\n","optimizer = optim.Adam([Matrix_X], lr=learning_rate_alpha)\n","#optimizer = optim.SGD([Matrix_X], lr=learning_rate_alpha)\n","\n","Best_MIS = 0\n","for iteration_t in range(number_of_iterations_T):\n","\n","    loss = loss_function_with_SDP(adjacency_matrix_tensor,adjacency_matrix_tensor_comp, Matrix_X,s_SDP_v_tensor, W_SDP_uv_tensor, gamma = 250, beta = 1)\n","\n","    optimizer.zero_grad()  # Clear gradients for the next iteration\n","    loss.backward()  # Backpropagation\n","    optimizer.step()  # Update the parameters\n","\n","    # Box-constraining:\n","    Matrix_X.data[Matrix_X>=1] =1\n","    Matrix_X.data[Matrix_X<=0] =0\n","\n","\n","    # Report the current MIS\n","    MIS = []\n","    for node in G.nodes:\n","        if Matrix_X[node] >0.1:\n","          MIS.append(node)\n","\n","    # If no MIS, move one\n","    if MIS_checker(MIS, G)[0] is False: MIS = []\n","\n","    ## Measuring the gradient sparsity: The results is that the gradient is never sparse\n","    #sparsity_ratio = ( Matrix_X.grad == 0.0).sum().item() / n\n","    #print(sparsity_ratio)\n","\n","    # Iteration logger every XX iterations:\n","    if (iteration_t + 1) % 200 == 0:\n","        print(f\"Step {iteration_t + 1}/{number_of_iterations_T}, IS: {MIS}, lr: {learning_rate_alpha}, Loss: {loss.item()}\")\n","\n","        #print(f\"Step {iteration_t + 1}/{number_of_iterations_T}, IS: {MIS}, lr: {learning_rate_alpha}, Loss: {loss.item()}, grad norm: {torch.norm(Matrix_X.grad).item()}\")\n","        #print(f\"Step {iteration_t + 1}/{number_of_iterations_T}, IS: {MIS}, lr: {learning_rate_alpha}, Loss: {loss.item()}\")\n","    if MIS_checker(MIS, G)[1] is True:\n","\n","      if len(MIS) > Best_MIS: # This is to save our current best so far\n","        Best_MIS = len(MIS)\n","\n","      l2_norm = torch.norm(Matrix_X - X_ini, p=2) # If a solution is found, measure its distance from initialization:\n","      print(\"+++++++++++ A MIS is found with size: \", [[[len(MIS)]]], \"++++ BEST so far\",[Best_MIS], \"Dist from Init: =\",l2_norm.item() , \"++++++++++++\", [MIS])\n","\n","\n","    #   #### Local restart every XX iterations:\n","\n","    #   Matrix_X.data[Matrix_X>0] = 0.8*torch.rand((1))\n","    #   Matrix_X.data[Matrix_X==0] = 0.2*torch.rand((1))\n","    #   X_ini = Matrix_X.data.clone()\n","    #   optimizer = optim.Adam([Matrix_X], lr=learning_rate_alpha)\n","\n","    # if iteration_t in Indicies_for_complete_restart:\n","    #     print(\"****************&&&&&&&&&&&&&****************&&&&&&&&&&&&& Restarting X Completely at RANDOM &&&&&&&&&&&&&&***************************&&&&&&&&&&&&&\")\n","    #     Matrix_X = (upper_bound - lower_bound) * torch.rand(n) + lower_bound\n","    #     Matrix_X.requires_grad_(True)\n","    #     X_ini = Matrix_X.data.clone()\n","    #     optimizer = optim.Adam([Matrix_X], lr=learning_rate_alpha)\n","\n","\n","      # # Restart X and the optimizer to search at a different point in [0,1]^n\n","\n","      # #lower_bound = 0.2\n","      # #upper_bound = 1.0\n","      # Matrix_X = (upper_bound - lower_bound) * torch.rand(n) + lower_bound\n","      # Matrix_X.requires_grad_(True)\n","\n","\n","      # #Matrix_X = torch.rand((n), requires_grad=True)\n","      # X_ini = Matrix_X.data.clone()\n","      # dict_of_inits[X_ini] = MIS\n","      # optimizer = optim.Adam([Matrix_X], lr=learning_rate_alpha)\n","      # #break\n","\n","      ##### Restart around the same point that we get from the SDP:\n","      mean_vector = X_SDP_init_tensor\n","      covariance_matrix = 1*torch.eye(len(mean_vector))\n","      Matrix_X = torch.normal(mean=mean_vector, std=torch.sqrt(torch.diag(covariance_matrix)))\n","      Matrix_X = Matrix_X.detach().clone()\n","      Matrix_X.data[Matrix_X>=1] =1\n","      Matrix_X.data[Matrix_X<=0] =0\n","      Matrix_X.requires_grad_(True)\n","      optimizer = optim.Adam([Matrix_X], lr=learning_rate_alpha)\n","      #optimizer = optim.SGD([Matrix_X], lr=learning_rate_alpha)\n","\n","\n","\n","# # Visualize the solution:\n","# node_colors = ['green' if node in MIS else 'blue' for node in G.nodes]\n","# nx.draw(G, with_labels=True, font_weight='bold', node_color=node_colors)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOqkMTWnYmErB0u7DVvOnpm","machine_shape":"hm","provenance":[{"file_id":"1U-syPVfCpUdbKhzt7Fl-NL9xKD3VLFUR","timestamp":1705707083534},{"file_id":"1IcEpXWTSVWZ4W9lCQj-yYoQG8CGmpyDg","timestamp":1705142448510}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}

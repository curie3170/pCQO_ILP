{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "datasets = []\n",
    "\n",
    "random_graph_directory = '../graphs/gnm_random_graphs/'\n",
    "for root, dirs, files in os.walk(random_graph_directory):\n",
    "    for filename in files:\n",
    "        name_string = filename[:-4]\n",
    "        graph_file_path = os.path.join(root, filename)\n",
    "\n",
    "        G = nx.read_gml(graph_file_path)\n",
    "\n",
    "        datasets.append(\n",
    "            {\n",
    "                \"name\": name_string,\n",
    "                \"graph\": nx.relabel.convert_node_labels_to_integers(\n",
    "                    G, first_label=1\n",
    "                ),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Solver Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers.dNNMIS import DNNMIS\n",
    "from solvers.dNNMIS_Subgraph import DNNMIS_SUBGRAPH\n",
    "from solvers.KaMIS import ReduMIS\n",
    "from solvers.ILPMIS import ILPMIS\n",
    "\n",
    "solvers = [\n",
    "    {\n",
    "        \"name\": \"dNN\",\n",
    "        \"class\": DNNMIS,\n",
    "        \"params\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"selection_criteria\": 0.8,\n",
    "            \"max_steps\": 25000,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dNN w/SG5k\",\n",
    "        \"class\": DNNMIS_SUBGRAPH,\n",
    "        \"params\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"selection_criteria\": 0.8,\n",
    "            \"max_steps\": 25000,\n",
    "            \"max_subgraph_steps\": 5000,\n",
    "        },\n",
    "    },\n",
    "    {\"name\": \"ReduMIS\", \"class\": ReduMIS, \"params\": {\"seed\": 13, \"time_limit\": 300}},\n",
    "    {\"name\": \"ILP\", \"class\": ILPMIS, \"params\": {}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Import Existing Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as outp:\n",
    "        return pickle.load(outp)\n",
    "    \n",
    "solutions = read_object(\"solutions.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Run New Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def benchmark(datasets, solvers):\n",
    "    solutions = []\n",
    "\n",
    "    stage = 0\n",
    "    stages = len(solvers) * len(datasets)\n",
    "\n",
    "    for solver in solvers:\n",
    "        for dataset in datasets:\n",
    "            solver_instance = solver[\"class\"](dataset[\"graph\"], solver[\"params\"])\n",
    "            solver_instance.solve()\n",
    "            solution = {\n",
    "                \"solution_method\": solver[\"name\"],\n",
    "                \"dataset_name\": dataset[\"name\"],\n",
    "                \"data\": deepcopy(solver_instance.solution),\n",
    "                \"time_taken\": deepcopy(solver_instance.solution_time),\n",
    "            }\n",
    "            solutions.append(solution)\n",
    "            del solver_instance\n",
    "            stage += 1\n",
    "            print(f\"Completed {stage} / {stages}\")\n",
    "\n",
    "    return solutions\n",
    "\n",
    "solutions = benchmark(datasets, solvers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_index = {k: v for v, k in enumerate([dataset[\"name\"] for dataset in datasets])}\n",
    "datasets_solutions = [[] for i in range(len(datasets))]\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for solution in solutions:\n",
    "    dsi = dataset_index[solution[\"dataset_name\"]]\n",
    "    datasets_solutions[dsi].append(solution)\n",
    "\n",
    "i = 0\n",
    "for dataset_solutions in datasets_solutions:\n",
    "    # IS CHECK\n",
    "    is_check = []\n",
    "    for solution in dataset_solutions:\n",
    "        IS_set = solution[\"data\"][\"graph_mask\"]\n",
    "        subgraph = datasets[dataset_index[solution[\"dataset_name\"]]][\"graph\"].subgraph(\n",
    "            IS_set\n",
    "        )\n",
    "        if len(subgraph.edges) > 0:\n",
    "            plt.figure(i)\n",
    "            plt.title(subgraph.edges)\n",
    "            i += 1\n",
    "            nx.draw(datasets[dataset_index[solution[\"dataset_name\"]]][\"graph\"], with_labels=True, node_color=IS_set)\n",
    "            is_check.append(False)\n",
    "            print(\n",
    "                f\"Non IS found using {solution['solution_method']} on {solution['dataset_name']}\"\n",
    "            )\n",
    "        else:\n",
    "            is_check.append(True)\n",
    "\n",
    "    table_row = [dataset_solutions[0]['dataset_name']]\n",
    "\n",
    "    table_row.extend([solution[\"data\"][\"size\"] for solution in dataset_solutions])\n",
    "    table_row.extend([solution[\"time_taken\"] for solution in dataset_solutions])\n",
    "    table_row.extend(is_check)\n",
    "\n",
    "    table_data.append(table_row)\n",
    "\n",
    "table_headers = [\"Dataset Name\"]\n",
    "\n",
    "table_headers.extend([solver[\"name\"] + \" Solution Size\" for solver in solvers])\n",
    "table_headers.extend([solver[\"name\"] + \" Solution Time\" for solver in solvers])\n",
    "table_headers.extend([solver[\"name\"] + \" Solution IS\" for solver in solvers])\n",
    "\n",
    "table = pandas.DataFrame(table_data, columns=table_headers)\n",
    "table\n",
    "table.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Find Exact Sets\n",
    "```{note}\n",
    "Result is indexed by 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dNN [7, 14]\n",
      "dNN w/SG5k [7, 14]\n",
      "ReduMIS [1, 7, 9, 10, 16]\n",
      "ILP [1, 7, 9, 10, 16]\n"
     ]
    }
   ],
   "source": [
    "graph_of_interest = \"GNM_n18_m77_seed6\"\n",
    "\n",
    "for dataset_solutions in datasets_solutions:\n",
    "    for solution in dataset_solutions:\n",
    "        if (solution[\"dataset_name\"] == graph_of_interest):\n",
    "            set_solution = []\n",
    "            for idx, x in enumerate(solution[\"data\"][\"graph_mask\"]):\n",
    "                if x == 1:\n",
    "                    set_solution.append(idx)\n",
    "            print(solution[\"solution_method\"],set_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Save Solutions to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as outp:  # Overwrites any existing file.\n",
    "        return pickle.load(outp)\n",
    "\n",
    "solutions = read_object(\"solutions.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

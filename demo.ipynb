{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataless Neural Network for MIS finding in Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate a random dense graph using NetworkX\n",
    "This will be the graph that we find the MIS of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "NUMBER_OF_NODES = 50\n",
    "NUMBER_OF_EDGES = 50\n",
    "SEED = 69\n",
    "\n",
    "G = nx.generators.dense_gnm_random_graph(NUMBER_OF_NODES, NUMBER_OF_EDGES, seed=SEED)\n",
    "\n",
    "nx.draw(G,with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate a neural network to solve your graph's MIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize neural network weights based on the nodes, edges, and complement edges of your graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import networkx as nx\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def datalessNN_graph_params(graph, seed=10, numpy_dtype=np.float32, torch_dtype=torch.float32):\n",
    "\n",
    "    ## Normalize graph labels to 0 - {Number of nodes} (this will help with indexing our graph-related weights)\n",
    "    G = nx.relabel.convert_node_labels_to_integers(graph)\n",
    "\n",
    "    \n",
    "\n",
    "    ## Set numpy seed. This is used for theta initialization\n",
    "    np.random.seed(seed=seed)\n",
    "\n",
    "    ## Graph order: number of nodes. Graph size: number of edges.\n",
    "    graph_order = len((G.nodes))\n",
    "    graph_size = len((G.edges))\n",
    "    graph_complement_size = (graph_order*(graph_order-1))//2 - graph_size\n",
    "\n",
    "    ##################################################################################################\n",
    "    ##################################################################################################\n",
    "    ################### MODIFY WEIGHTS of NN_p BASED ON GRAPH\n",
    "    ##################################################################################################\n",
    "    ##################################################################################################\n",
    "\n",
    "    ##############################\n",
    "    ## Theta value initilization\n",
    "    ##############################\n",
    "    list_of_node_degrees = [None]*graph_order\n",
    "    for i in range(0, graph_order):\n",
    "        list_of_node_degrees[i] = G.degree[i]\n",
    "    \n",
    "    max_node_degree_in_graph = np.max(list_of_node_degrees)\n",
    "\n",
    "    theta_vector = np.zeros(graph_order, dtype=numpy_dtype)\n",
    "\n",
    "    for i in range(0, graph_order):\n",
    "        ## To prevent exact repititive probability: add some very small epsilon\n",
    "        theta_vector[i] = (\n",
    "            1 - (list_of_node_degrees[i] / max_node_degree_in_graph) + np.random.uniform(low=0.0, high=0.1)\n",
    "        )\n",
    "\n",
    "    ###############################################\n",
    "    ## Second layer weight and bias initilization\n",
    "    ###############################################\n",
    "\n",
    "    #### This is the numpy array we need to update the weights of the second layer (N x (N+M+Mc))\n",
    "    second_layer_weights = np.zeros(shape=(graph_order, graph_order + graph_size + graph_complement_size), dtype=numpy_dtype)\n",
    "\n",
    "    #### Initilize the portion of the weight matrix reserved for the nodes of G\n",
    "    for i in range(graph_order):\n",
    "        second_layer_weights[i, i] = 1.0  # this stays the same\n",
    "\n",
    "\n",
    "    #### Initilize the portion of the weight matrix reserved for the edges of G\n",
    "    for idx, pair in enumerate(G.edges):\n",
    "        second_layer_weights[pair[0], graph_order + idx] = 1.0\n",
    "        second_layer_weights[pair[1], graph_order + idx] = 1.0\n",
    "\n",
    "    #### Initilize the portion of the weight matrix reserved for the edges of G'\n",
    "    G_complement = nx.complement(G)\n",
    "    for idx, pair in enumerate(G_complement.edges):\n",
    "        second_layer_weights[pair[0], graph_order + graph_size + idx] = 1.0\n",
    "        second_layer_weights[pair[1], graph_order + graph_size + idx] = 1.0\n",
    "    del G_complement\n",
    "\n",
    "\n",
    "    #### This is the numpy array we need to update the biases of the second layer (N+M+Mc)\n",
    "    second_layer_biases = np.zeros(shape=(graph_order + graph_size + graph_complement_size), dtype=numpy_dtype)\n",
    "\n",
    "    ## Initilize the portion of the bias vector reserved for the nodes of G\n",
    "    second_layer_biases[0:graph_order] = -0.5\n",
    "\n",
    "    ## Initilize the portion of the bias vector reserved for the edges of G and G'\n",
    "    second_layer_biases[\n",
    "        graph_order : graph_order + graph_size + graph_complement_size\n",
    "    ] = -1.0\n",
    "\n",
    "    ##############################################\n",
    "    ## Third layer weight initilization\n",
    "    ##############################################\n",
    "\n",
    "    #### This is the numpy array we need to update the weights of the third layer (N+M+Mc)\n",
    "    third_layer_weights = np.zeros(shape=(graph_order + graph_size + graph_complement_size), dtype=numpy_dtype)\n",
    "\n",
    "\n",
    "    #### add here from graph:\n",
    "    third_layer_weights[0:graph_order] = -1.0\n",
    "    third_layer_weights[graph_order : graph_order + graph_size] = graph_order\n",
    "    third_layer_weights[graph_order + graph_size :] = -1.0\n",
    "\n",
    "    T_1 = torch.clamp(torch.tensor(theta_vector, dtype=torch_dtype), 0.1, 0.9)\n",
    "    W_2 = torch.tensor(second_layer_weights, dtype=torch_dtype)\n",
    "    B_2 = torch.tensor(second_layer_biases, dtype=torch_dtype)\n",
    "    W_3 = torch.tensor(third_layer_weights, dtype=torch_dtype)\n",
    "\n",
    "    return {\"theta_tensor\": T_1, \"layer_2_weights\": W_2, \"layer_2_biases\": B_2, \"layer_3_weights\": W_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize neural network structure using the weights we found earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class ElementwiseMultiply(torch.nn.Module):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, in_features, out_features, lower_bound=0, upper_bound=1):\n",
    "        super().__init__()\n",
    "        self.in_features, self.out_features = in_features, out_features\n",
    "        weights = torch.Tensor(in_features, out_features)\n",
    "        self.weight = torch.nn.Parameter(weights)\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "\n",
    "    def forward(self, x):        \n",
    "        # Perform element-wise multiplication\n",
    "        result = torch.mul(torch.Tensor(x), self.weight.t())\n",
    "        \n",
    "        # Bound the output between the specified lower and upper bounds\n",
    "        result = torch.clamp(result, self.lower_bound, self.upper_bound)\n",
    "        return result\n",
    "    \n",
    "class ZeroOneClamp(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, module):\n",
    "        w = module.weight.data\n",
    "        module.weight.data = torch.clamp(w, 0, 1)\n",
    "\n",
    "\n",
    "def datalessNN(theta_tensor, layer2_weights, layer2_biases, layer3_weights, numpy_dype=np.float32, torch_dtype=torch.float32):\n",
    "\n",
    "    graph_order = len(theta_tensor)\n",
    "    graph_nodes_and_all_possible_edges = len(layer2_biases)\n",
    "\n",
    "    ##################################################################3################################################\n",
    "    ################################3 initialize NN ##################################################################3\n",
    "    ##################################################################3################################################\n",
    "\n",
    "    NN = torch.nn.Sequential()\n",
    "\n",
    "    ###############################\n",
    "    ## Theta Layer initialization\n",
    "    ###############################\n",
    "    theta_layer = ElementwiseMultiply(in_features=graph_order, out_features=graph_order)\n",
    "\n",
    "    # Temporarily disable gradient calc to set initial weights\n",
    "    with torch.no_grad():\n",
    "        theta_layer.weight.data = theta_tensor\n",
    "\n",
    "    NN.append(theta_layer)\n",
    "\n",
    "    ################################\n",
    "    ## Second Layer initialization\n",
    "    ################################\n",
    "    layer2 = torch.nn.Linear(\n",
    "        in_features=graph_order,\n",
    "        out_features=graph_nodes_and_all_possible_edges,\n",
    "        bias=True,\n",
    "        dtype=torch_dtype\n",
    "    )\n",
    "    # add ReLu activation layer to layer 2\n",
    "    layer2_activation = torch.nn.ReLU()\n",
    "\n",
    "    # make layer non-trainable\n",
    "    layer2.requires_grad_(False)\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    layer2.weight.data = np.transpose(layer2_weights)\n",
    "    layer2.bias.data = layer2_biases\n",
    "\n",
    "    NN.append(layer2)\n",
    "    NN.append(layer2_activation)\n",
    "\n",
    "    ###############################\n",
    "    ## Third Layer initialization\n",
    "    ###############################\n",
    "    layer3 = torch.nn.Linear(\n",
    "        in_features=graph_nodes_and_all_possible_edges, out_features=1, bias=False\n",
    "    )\n",
    "\n",
    "    # make layer non-trainable\n",
    "    layer3.requires_grad_(False)\n",
    "\n",
    "    # Initialize weights\n",
    "    layer3.weight.data = layer3_weights\n",
    "    \n",
    "    NN.append(layer3)\n",
    "\n",
    "    return NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform an optimization using the structure and weights to determine the MIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_step =  0 value =  tensor(-135.1046, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1 value =  tensor(-148.6160, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  2 value =  tensor(-162.2344, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  3 value =  tensor(-175.2193, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  4 value =  tensor(-188.1654, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  5 value =  tensor(-200.0238, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  6 value =  tensor(-210.0400, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  7 value =  tensor(-219.9971, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  8 value =  tensor(-230.3318, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  9 value =  tensor(-240.5416, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  10 value =  tensor(-250.0695, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  11 value =  tensor(-255.5023, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  12 value =  tensor(-260.7770, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  13 value =  tensor(-266.1537, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  14 value =  tensor(-270.1446, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  15 value =  tensor(-273.2558, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  16 value =  tensor(-277.4443, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  17 value =  tensor(-279.4589, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  18 value =  tensor(-281.8185, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  19 value =  tensor(-284.2946, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  20 value =  tensor(-287.2894, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  21 value =  tensor(-290.4326, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  22 value =  tensor(-293.6304, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  23 value =  tensor(-296.2622, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  24 value =  tensor(-299.4346, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  25 value =  tensor(-302.9509, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  26 value =  tensor(-306.6655, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  27 value =  tensor(-310.2613, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  28 value =  tensor(-313.4470, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  29 value =  tensor(-317.0366, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  30 value =  tensor(-320.3068, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  31 value =  tensor(-322.7784, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  32 value =  tensor(-324.9589, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  33 value =  tensor(-326.8756, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  34 value =  tensor(-328.4119, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  35 value =  tensor(-330.3347, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  36 value =  tensor(-332.3687, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  37 value =  tensor(-334.4412, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  38 value =  tensor(-336.7773, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  39 value =  tensor(-338.9045, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  40 value =  tensor(-340.8749, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  41 value =  tensor(-342.2202, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  42 value =  tensor(-343.4729, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  43 value =  tensor(-344.4677, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  44 value =  tensor(-345.4750, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  45 value =  tensor(-346.5137, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  46 value =  tensor(-348.2923, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  47 value =  tensor(-349.6188, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  48 value =  tensor(-350.5035, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  49 value =  tensor(-351.5381, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  50 value =  tensor(-352.4574, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  51 value =  tensor(-353.4866, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  52 value =  tensor(-354.5928, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  53 value =  tensor(-355.7663, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  54 value =  tensor(-356.5809, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  55 value =  tensor(-357.3832, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  56 value =  tensor(-358.2436, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  57 value =  tensor(-359.5505, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  58 value =  tensor(-360.9144, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  59 value =  tensor(-361.4585, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  60 value =  tensor(-362.2488, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  61 value =  tensor(-363.0806, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  62 value =  tensor(-364.1357, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  63 value =  tensor(-365.3439, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  64 value =  tensor(-366.2512, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  65 value =  tensor(-367.3285, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  66 value =  tensor(-368.1483, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  67 value =  tensor(-368.8445, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  68 value =  tensor(-369.5528, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  69 value =  tensor(-370.2847, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  70 value =  tensor(-370.6718, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  71 value =  tensor(-371.3781, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  72 value =  tensor(-371.8683, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  73 value =  tensor(-372.2645, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  74 value =  tensor(-372.8177, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  75 value =  tensor(-373.4639, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  76 value =  tensor(-374.1904, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  77 value =  tensor(-374.6586, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  78 value =  tensor(-375.3726, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  79 value =  tensor(-375.8133, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  80 value =  tensor(-376.2211, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  81 value =  tensor(-376.9540, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  82 value =  tensor(-377.5290, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  83 value =  tensor(-378.2170, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  84 value =  tensor(-378.7674, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  85 value =  tensor(-379.3576, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  86 value =  tensor(-379.8974, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  87 value =  tensor(-380.5221, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  88 value =  tensor(-381.3424, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  89 value =  tensor(-382.0496, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  90 value =  tensor(-382.6368, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  91 value =  tensor(-383.2889, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  92 value =  tensor(-383.9071, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  93 value =  tensor(-384.6751, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  94 value =  tensor(-385.4312, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  95 value =  tensor(-386.0322, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  96 value =  tensor(-386.4772, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  97 value =  tensor(-386.8166, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  98 value =  tensor(-387.0314, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  99 value =  tensor(-387.5907, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  100 value =  tensor(-388.4696, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  101 value =  tensor(-388.7953, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  102 value =  tensor(-388.9102, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  103 value =  tensor(-389.5099, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  104 value =  tensor(-389.8262, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  105 value =  tensor(-390.2336, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  106 value =  tensor(-390.7584, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  107 value =  tensor(-391.0914, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  108 value =  tensor(-391.4640, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  109 value =  tensor(-391.8245, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  110 value =  tensor(-392.4112, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  111 value =  tensor(-392.7155, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  112 value =  tensor(-392.9626, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  113 value =  tensor(-393.3710, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  114 value =  tensor(-393.8828, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  115 value =  tensor(-394.3404, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  116 value =  tensor(-394.8291, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  117 value =  tensor(-395.1722, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  118 value =  tensor(-395.5596, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  119 value =  tensor(-395.9008, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  120 value =  tensor(-396.1835, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  121 value =  tensor(-396.4432, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  122 value =  tensor(-396.7130, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  123 value =  tensor(-397.1740, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  124 value =  tensor(-397.3047, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  125 value =  tensor(-397.7691, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  126 value =  tensor(-398.0582, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  127 value =  tensor(-398.2546, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  128 value =  tensor(-398.6471, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  129 value =  tensor(-398.9420, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  130 value =  tensor(-399.1685, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  131 value =  tensor(-399.4464, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  132 value =  tensor(-399.6596, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  133 value =  tensor(-399.9289, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  134 value =  tensor(-400.2545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  135 value =  tensor(-400.7072, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  136 value =  tensor(-401.3236, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  137 value =  tensor(-401.4643, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  138 value =  tensor(-401.6180, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  139 value =  tensor(-402.0187, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  140 value =  tensor(-402.3235, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  141 value =  tensor(-402.7112, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  142 value =  tensor(-403.0630, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  143 value =  tensor(-403.3686, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  144 value =  tensor(-403.5139, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  145 value =  tensor(-404.0757, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  146 value =  tensor(-404.4599, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  147 value =  tensor(-404.3415, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  148 value =  tensor(-404.5477, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  149 value =  tensor(-405.0286, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  150 value =  tensor(-405.2935, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  151 value =  tensor(-405.5379, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  152 value =  tensor(-405.9949, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  153 value =  tensor(-406.2064, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  154 value =  tensor(-406.5762, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  155 value =  tensor(-406.9025, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  156 value =  tensor(-407.3123, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  157 value =  tensor(-407.5175, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  158 value =  tensor(-407.6736, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  159 value =  tensor(-407.9492, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  160 value =  tensor(-408.1156, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  161 value =  tensor(-408.3738, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  162 value =  tensor(-408.5042, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  163 value =  tensor(-408.9495, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  164 value =  tensor(-409.1352, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  165 value =  tensor(-408.9657, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  166 value =  tensor(-409.1198, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  167 value =  tensor(-409.4111, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  168 value =  tensor(-409.4951, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  169 value =  tensor(-409.5494, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  170 value =  tensor(-409.7567, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  171 value =  tensor(-410.0315, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  172 value =  tensor(-410.0185, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  173 value =  tensor(-410.1436, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  174 value =  tensor(-410.4254, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  175 value =  tensor(-410.4968, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  176 value =  tensor(-410.5824, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  177 value =  tensor(-410.6732, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  178 value =  tensor(-411.0672, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  179 value =  tensor(-411.0955, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  180 value =  tensor(-411.2420, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  181 value =  tensor(-411.2981, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  182 value =  tensor(-411.5331, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  183 value =  tensor(-411.6441, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  184 value =  tensor(-411.9034, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  185 value =  tensor(-412.0558, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  186 value =  tensor(-412.1296, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  187 value =  tensor(-411.8885, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  188 value =  tensor(-412.0461, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  189 value =  tensor(-412.2298, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  190 value =  tensor(-412.5100, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  191 value =  tensor(-412.6997, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  192 value =  tensor(-412.5569, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  193 value =  tensor(-412.7211, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  194 value =  tensor(-412.8384, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  195 value =  tensor(-412.8792, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  196 value =  tensor(-412.9901, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  197 value =  tensor(-412.9365, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  198 value =  tensor(-413.0183, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  199 value =  tensor(-413.2665, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  200 value =  tensor(-413.4150, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  201 value =  tensor(-413.5415, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  202 value =  tensor(-413.5406, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  203 value =  tensor(-413.6078, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  204 value =  tensor(-413.7809, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  205 value =  tensor(-413.7882, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  206 value =  tensor(-413.9545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  207 value =  tensor(-414.0324, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  208 value =  tensor(-414.1140, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  209 value =  tensor(-414.1476, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  210 value =  tensor(-414.1102, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  211 value =  tensor(-414.0881, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  212 value =  tensor(-414.1898, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  213 value =  tensor(-414.2072, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  214 value =  tensor(-414.2654, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  215 value =  tensor(-414.3342, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  216 value =  tensor(-414.3107, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  217 value =  tensor(-414.4607, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  218 value =  tensor(-414.4131, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  219 value =  tensor(-414.4272, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  220 value =  tensor(-414.4335, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  221 value =  tensor(-414.5128, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  222 value =  tensor(-414.6298, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  223 value =  tensor(-414.5489, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  224 value =  tensor(-414.6786, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  225 value =  tensor(-414.8462, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  226 value =  tensor(-414.8389, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  227 value =  tensor(-414.8275, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  228 value =  tensor(-414.8703, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  229 value =  tensor(-415.0607, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  230 value =  tensor(-414.9515, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  231 value =  tensor(-414.8666, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  232 value =  tensor(-414.9213, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  233 value =  tensor(-415.1371, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  234 value =  tensor(-415.1450, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  235 value =  tensor(-415.2051, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  236 value =  tensor(-415.1888, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  237 value =  tensor(-415.1098, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  238 value =  tensor(-415.2078, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  239 value =  tensor(-415.2700, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  240 value =  tensor(-415.4160, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  241 value =  tensor(-415.4490, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  242 value =  tensor(-415.3293, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  243 value =  tensor(-415.4063, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  244 value =  tensor(-415.5177, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  245 value =  tensor(-415.5574, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  246 value =  tensor(-415.6151, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  247 value =  tensor(-415.6212, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  248 value =  tensor(-415.7385, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  249 value =  tensor(-415.7977, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  250 value =  tensor(-415.7332, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  251 value =  tensor(-415.7543, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  252 value =  tensor(-415.6935, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  253 value =  tensor(-415.6435, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  254 value =  tensor(-415.6559, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  255 value =  tensor(-415.8098, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  256 value =  tensor(-415.9357, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  257 value =  tensor(-415.8535, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  258 value =  tensor(-415.7291, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  259 value =  tensor(-415.8146, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  260 value =  tensor(-415.9245, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  261 value =  tensor(-415.7403, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  262 value =  tensor(-415.7838, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  263 value =  tensor(-415.7739, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  264 value =  tensor(-415.7957, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  265 value =  tensor(-415.6873, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  266 value =  tensor(-415.7084, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  267 value =  tensor(-415.7921, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  268 value =  tensor(-415.9545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  269 value =  tensor(-415.7474, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  270 value =  tensor(-415.8788, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  271 value =  tensor(-415.8401, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  272 value =  tensor(-415.7574, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  273 value =  tensor(-415.8381, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  274 value =  tensor(-415.8680, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  275 value =  tensor(-415.8668, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  276 value =  tensor(-415.8178, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  277 value =  tensor(-415.9279, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  278 value =  tensor(-416.0240, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  279 value =  tensor(-415.9188, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  280 value =  tensor(-415.8616, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  281 value =  tensor(-415.9125, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  282 value =  tensor(-415.8918, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  283 value =  tensor(-415.9765, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  284 value =  tensor(-415.9305, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  285 value =  tensor(-415.9572, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  286 value =  tensor(-416.0187, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  287 value =  tensor(-416.0369, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  288 value =  tensor(-415.9484, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  289 value =  tensor(-415.9404, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  290 value =  tensor(-415.9881, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  291 value =  tensor(-415.9227, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  292 value =  tensor(-415.9428, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  293 value =  tensor(-416.0907, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  294 value =  tensor(-415.9727, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  295 value =  tensor(-416.0323, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  296 value =  tensor(-416.0821, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  297 value =  tensor(-416.0331, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  298 value =  tensor(-415.9711, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  299 value =  tensor(-416.0245, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  300 value =  tensor(-416.1224, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  301 value =  tensor(-416.1730, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  302 value =  tensor(-416.1513, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  303 value =  tensor(-416.1873, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  304 value =  tensor(-416.1587, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  305 value =  tensor(-416.0497, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  306 value =  tensor(-416.1935, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  307 value =  tensor(-416.1130, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  308 value =  tensor(-416.1297, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  309 value =  tensor(-416.0751, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  310 value =  tensor(-416.0287, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  311 value =  tensor(-416.1166, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  312 value =  tensor(-416.1502, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  313 value =  tensor(-416.1946, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  314 value =  tensor(-416.2163, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  315 value =  tensor(-416.2187, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  316 value =  tensor(-416.3001, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  317 value =  tensor(-416.1961, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  318 value =  tensor(-416.2166, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  319 value =  tensor(-416.2360, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  320 value =  tensor(-416.2206, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  321 value =  tensor(-416.1346, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  322 value =  tensor(-416.0913, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  323 value =  tensor(-416.0429, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  324 value =  tensor(-416.2155, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  325 value =  tensor(-416.2429, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  326 value =  tensor(-415.9619, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  327 value =  tensor(-415.8610, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  328 value =  tensor(-416.0304, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  329 value =  tensor(-416.1034, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  330 value =  tensor(-416.1092, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  331 value =  tensor(-416.0311, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  332 value =  tensor(-416.0994, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  333 value =  tensor(-416.2139, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  334 value =  tensor(-416.1672, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  335 value =  tensor(-416.0560, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  336 value =  tensor(-416.1400, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  337 value =  tensor(-416.1891, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  338 value =  tensor(-416.2340, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  339 value =  tensor(-416.2921, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  340 value =  tensor(-416.2192, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  341 value =  tensor(-416.1884, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  342 value =  tensor(-416.2199, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  343 value =  tensor(-416.3156, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  344 value =  tensor(-416.3572, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  345 value =  tensor(-416.2653, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  346 value =  tensor(-416.1772, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  347 value =  tensor(-416.1784, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  348 value =  tensor(-416.2020, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  349 value =  tensor(-416.1762, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  350 value =  tensor(-416.2352, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  351 value =  tensor(-416.2632, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  352 value =  tensor(-416.3261, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  353 value =  tensor(-416.1899, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  354 value =  tensor(-416.3269, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  355 value =  tensor(-416.3317, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  356 value =  tensor(-416.2506, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  357 value =  tensor(-416.2658, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  358 value =  tensor(-416.2920, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  359 value =  tensor(-416.3432, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  360 value =  tensor(-416.3410, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  361 value =  tensor(-416.2614, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  362 value =  tensor(-416.3024, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  363 value =  tensor(-416.4640, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  364 value =  tensor(-416.4799, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  365 value =  tensor(-416.4409, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  366 value =  tensor(-416.5057, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  367 value =  tensor(-416.3871, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  368 value =  tensor(-416.2330, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  369 value =  tensor(-416.2366, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  370 value =  tensor(-416.3731, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  371 value =  tensor(-416.3221, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  372 value =  tensor(-416.3096, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  373 value =  tensor(-416.3268, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  374 value =  tensor(-416.3902, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  375 value =  tensor(-416.4710, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  376 value =  tensor(-416.4571, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  377 value =  tensor(-416.4397, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  378 value =  tensor(-416.4575, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  379 value =  tensor(-416.4403, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  380 value =  tensor(-416.5062, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  381 value =  tensor(-416.3032, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  382 value =  tensor(-416.3952, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  383 value =  tensor(-416.5337, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  384 value =  tensor(-416.5758, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  385 value =  tensor(-416.4604, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  386 value =  tensor(-416.5599, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  387 value =  tensor(-416.4427, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  388 value =  tensor(-416.4221, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  389 value =  tensor(-416.5545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  390 value =  tensor(-416.5554, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  391 value =  tensor(-416.5653, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  392 value =  tensor(-416.4827, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  393 value =  tensor(-416.5522, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  394 value =  tensor(-416.5416, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  395 value =  tensor(-416.4675, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  396 value =  tensor(-416.5532, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  397 value =  tensor(-416.5504, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  398 value =  tensor(-416.4568, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  399 value =  tensor(-416.4545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  400 value =  tensor(-416.5353, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  401 value =  tensor(-416.6459, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  402 value =  tensor(-416.7763, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  403 value =  tensor(-416.9577, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  404 value =  tensor(-416.8335, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  405 value =  tensor(-416.7960, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  406 value =  tensor(-417.0179, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  407 value =  tensor(-417.1349, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  408 value =  tensor(-417.0457, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  409 value =  tensor(-417.1462, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  410 value =  tensor(-417.2338, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  411 value =  tensor(-417.0401, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  412 value =  tensor(-417.1012, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  413 value =  tensor(-417.2635, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  414 value =  tensor(-417.2307, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  415 value =  tensor(-417.3596, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  416 value =  tensor(-417.3467, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  417 value =  tensor(-417.3448, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  418 value =  tensor(-417.2975, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  419 value =  tensor(-417.3782, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  420 value =  tensor(-417.5039, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  421 value =  tensor(-417.5180, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  422 value =  tensor(-417.4013, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  423 value =  tensor(-417.5593, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  424 value =  tensor(-417.5581, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  425 value =  tensor(-417.4340, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  426 value =  tensor(-417.6739, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  427 value =  tensor(-417.5740, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  428 value =  tensor(-417.5034, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  429 value =  tensor(-417.2000, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  430 value =  tensor(-417.3094, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  431 value =  tensor(-417.4651, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  432 value =  tensor(-417.5687, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  433 value =  tensor(-417.5359, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  434 value =  tensor(-417.5371, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  435 value =  tensor(-417.3444, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  436 value =  tensor(-417.5040, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  437 value =  tensor(-417.7224, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  438 value =  tensor(-417.9175, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  439 value =  tensor(-417.6839, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  440 value =  tensor(-417.6578, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  441 value =  tensor(-417.7248, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  442 value =  tensor(-417.7838, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  443 value =  tensor(-417.8956, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  444 value =  tensor(-418.0826, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  445 value =  tensor(-418.0096, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  446 value =  tensor(-418.1051, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  447 value =  tensor(-417.9511, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  448 value =  tensor(-417.9475, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  449 value =  tensor(-418.2610, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  450 value =  tensor(-418.3468, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  451 value =  tensor(-418.1377, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  452 value =  tensor(-418.0819, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  453 value =  tensor(-418.1838, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  454 value =  tensor(-418.2132, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  455 value =  tensor(-418.2968, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  456 value =  tensor(-418.1824, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  457 value =  tensor(-418.3575, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  458 value =  tensor(-418.4525, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  459 value =  tensor(-418.4597, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  460 value =  tensor(-418.4763, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  461 value =  tensor(-418.6096, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  462 value =  tensor(-418.7452, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  463 value =  tensor(-418.6258, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  464 value =  tensor(-418.6483, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  465 value =  tensor(-418.6279, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  466 value =  tensor(-418.6227, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  467 value =  tensor(-418.7676, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  468 value =  tensor(-418.9992, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  469 value =  tensor(-418.7289, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  470 value =  tensor(-418.5700, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  471 value =  tensor(-418.6791, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  472 value =  tensor(-418.8529, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  473 value =  tensor(-418.9449, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  474 value =  tensor(-418.8783, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  475 value =  tensor(-418.8005, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  476 value =  tensor(-418.7112, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  477 value =  tensor(-418.7900, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  478 value =  tensor(-419.0556, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  479 value =  tensor(-419.1179, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  480 value =  tensor(-419.2010, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  481 value =  tensor(-419.0443, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  482 value =  tensor(-419.1931, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  483 value =  tensor(-419.1330, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  484 value =  tensor(-419.0707, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  485 value =  tensor(-419.1888, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  486 value =  tensor(-419.3186, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  487 value =  tensor(-419.3521, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  488 value =  tensor(-419.3721, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  489 value =  tensor(-419.4475, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  490 value =  tensor(-419.4869, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  491 value =  tensor(-419.5471, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  492 value =  tensor(-419.6067, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  493 value =  tensor(-419.5432, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  494 value =  tensor(-419.6748, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  495 value =  tensor(-419.6745, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  496 value =  tensor(-419.7551, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  497 value =  tensor(-419.7132, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  498 value =  tensor(-419.8023, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  499 value =  tensor(-419.6931, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  500 value =  tensor(-419.5675, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  501 value =  tensor(-419.6923, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  502 value =  tensor(-419.7992, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  503 value =  tensor(-419.7029, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  504 value =  tensor(-419.6211, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  505 value =  tensor(-419.5377, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  506 value =  tensor(-419.6243, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  507 value =  tensor(-419.5979, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  508 value =  tensor(-419.6902, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  509 value =  tensor(-419.5341, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  510 value =  tensor(-419.5233, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  511 value =  tensor(-419.8066, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  512 value =  tensor(-419.7530, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  513 value =  tensor(-419.7478, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  514 value =  tensor(-419.5854, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  515 value =  tensor(-419.5695, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  516 value =  tensor(-419.6209, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  517 value =  tensor(-419.6990, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  518 value =  tensor(-419.5735, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  519 value =  tensor(-419.5601, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  520 value =  tensor(-419.5892, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  521 value =  tensor(-419.6173, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  522 value =  tensor(-419.6577, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  523 value =  tensor(-419.5624, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  524 value =  tensor(-419.6845, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  525 value =  tensor(-419.6329, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  526 value =  tensor(-419.4945, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  527 value =  tensor(-419.5512, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  528 value =  tensor(-419.6509, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  529 value =  tensor(-419.6585, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  530 value =  tensor(-419.6532, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  531 value =  tensor(-419.6564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  532 value =  tensor(-419.6868, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  533 value =  tensor(-419.6121, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  534 value =  tensor(-419.8577, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  535 value =  tensor(-419.9754, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  536 value =  tensor(-419.7930, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  537 value =  tensor(-419.7955, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  538 value =  tensor(-419.7756, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  539 value =  tensor(-419.8124, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  540 value =  tensor(-419.8306, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  541 value =  tensor(-419.8680, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  542 value =  tensor(-419.9289, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  543 value =  tensor(-419.9368, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  544 value =  tensor(-419.8043, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  545 value =  tensor(-419.8416, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  546 value =  tensor(-419.7950, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  547 value =  tensor(-419.6812, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  548 value =  tensor(-419.6398, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  549 value =  tensor(-419.7303, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  550 value =  tensor(-419.6290, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  551 value =  tensor(-419.7224, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  552 value =  tensor(-419.8016, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  553 value =  tensor(-419.6784, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  554 value =  tensor(-419.6154, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  555 value =  tensor(-419.6826, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  556 value =  tensor(-419.7374, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  557 value =  tensor(-419.8806, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  558 value =  tensor(-419.6114, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  559 value =  tensor(-419.5675, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  560 value =  tensor(-419.7316, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  561 value =  tensor(-419.7278, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  562 value =  tensor(-419.5568, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  563 value =  tensor(-419.5366, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  564 value =  tensor(-419.7336, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  565 value =  tensor(-419.8167, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  566 value =  tensor(-419.6414, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  567 value =  tensor(-419.5806, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  568 value =  tensor(-419.7631, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  569 value =  tensor(-419.5674, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  570 value =  tensor(-419.5730, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  571 value =  tensor(-419.6477, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  572 value =  tensor(-419.4879, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  573 value =  tensor(-419.6127, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  574 value =  tensor(-419.6376, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  575 value =  tensor(-419.5384, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  576 value =  tensor(-419.6796, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  577 value =  tensor(-419.6668, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  578 value =  tensor(-419.6428, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  579 value =  tensor(-419.4825, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  580 value =  tensor(-419.6142, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  581 value =  tensor(-419.6368, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  582 value =  tensor(-419.7121, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  583 value =  tensor(-419.8724, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  584 value =  tensor(-419.6383, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  585 value =  tensor(-419.5408, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  586 value =  tensor(-419.4353, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  587 value =  tensor(-419.5119, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  588 value =  tensor(-419.7685, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  589 value =  tensor(-419.6458, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  590 value =  tensor(-419.5444, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  591 value =  tensor(-419.4805, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  592 value =  tensor(-419.5122, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  593 value =  tensor(-419.4841, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  594 value =  tensor(-419.6125, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  595 value =  tensor(-419.4492, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  596 value =  tensor(-419.4120, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  597 value =  tensor(-419.5688, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  598 value =  tensor(-419.7299, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  599 value =  tensor(-419.5684, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  600 value =  tensor(-419.5221, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  601 value =  tensor(-419.6135, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  602 value =  tensor(-419.6771, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  603 value =  tensor(-419.6165, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  604 value =  tensor(-419.5504, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  605 value =  tensor(-419.5005, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  606 value =  tensor(-419.5733, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  607 value =  tensor(-419.6866, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  608 value =  tensor(-419.7626, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  609 value =  tensor(-419.4860, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  610 value =  tensor(-419.4288, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  611 value =  tensor(-419.5490, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  612 value =  tensor(-419.7695, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  613 value =  tensor(-419.6906, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  614 value =  tensor(-419.3668, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  615 value =  tensor(-419.5919, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  616 value =  tensor(-419.6125, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  617 value =  tensor(-419.5645, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  618 value =  tensor(-419.5065, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  619 value =  tensor(-419.6160, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  620 value =  tensor(-419.4923, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  621 value =  tensor(-419.4520, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  622 value =  tensor(-419.6219, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  623 value =  tensor(-419.7295, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  624 value =  tensor(-419.4669, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  625 value =  tensor(-419.5180, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  626 value =  tensor(-419.4868, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  627 value =  tensor(-419.4970, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  628 value =  tensor(-419.5255, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  629 value =  tensor(-419.6232, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  630 value =  tensor(-419.7620, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  631 value =  tensor(-419.7065, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  632 value =  tensor(-419.5364, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  633 value =  tensor(-419.5493, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  634 value =  tensor(-419.7021, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  635 value =  tensor(-419.6628, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  636 value =  tensor(-419.6311, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  637 value =  tensor(-419.6349, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  638 value =  tensor(-419.7519, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  639 value =  tensor(-419.7552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  640 value =  tensor(-419.7340, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  641 value =  tensor(-419.7682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  642 value =  tensor(-419.9297, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  643 value =  tensor(-419.8859, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  644 value =  tensor(-419.6112, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  645 value =  tensor(-419.7865, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  646 value =  tensor(-419.8716, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  647 value =  tensor(-419.6638, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  648 value =  tensor(-419.5197, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  649 value =  tensor(-419.6160, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  650 value =  tensor(-419.7422, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  651 value =  tensor(-419.7904, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  652 value =  tensor(-419.6620, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  653 value =  tensor(-419.6459, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  654 value =  tensor(-419.6073, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  655 value =  tensor(-419.6401, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  656 value =  tensor(-419.8532, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  657 value =  tensor(-419.7160, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  658 value =  tensor(-419.5057, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  659 value =  tensor(-419.4668, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  660 value =  tensor(-419.5778, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  661 value =  tensor(-419.5763, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  662 value =  tensor(-419.7552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  663 value =  tensor(-419.7302, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  664 value =  tensor(-419.6698, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  665 value =  tensor(-419.6378, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  666 value =  tensor(-419.5958, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  667 value =  tensor(-419.6371, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  668 value =  tensor(-419.7688, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  669 value =  tensor(-419.8492, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  670 value =  tensor(-419.7387, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  671 value =  tensor(-419.8580, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  672 value =  tensor(-419.4806, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  673 value =  tensor(-419.3876, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  674 value =  tensor(-419.6355, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  675 value =  tensor(-419.8262, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  676 value =  tensor(-419.7776, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  677 value =  tensor(-419.7849, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  678 value =  tensor(-419.7041, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  679 value =  tensor(-419.6519, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  680 value =  tensor(-419.6324, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  681 value =  tensor(-419.6833, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  682 value =  tensor(-419.6979, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  683 value =  tensor(-419.7032, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  684 value =  tensor(-419.7670, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  685 value =  tensor(-419.4742, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  686 value =  tensor(-419.5654, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  687 value =  tensor(-419.7998, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  688 value =  tensor(-419.7338, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  689 value =  tensor(-419.7188, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  690 value =  tensor(-419.8271, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  691 value =  tensor(-419.8444, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  692 value =  tensor(-419.6808, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  693 value =  tensor(-419.7461, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  694 value =  tensor(-419.8779, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  695 value =  tensor(-419.6902, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  696 value =  tensor(-419.6605, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  697 value =  tensor(-419.7473, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  698 value =  tensor(-419.6836, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  699 value =  tensor(-419.6216, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  700 value =  tensor(-419.7425, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  701 value =  tensor(-419.7890, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  702 value =  tensor(-419.6801, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  703 value =  tensor(-419.6981, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  704 value =  tensor(-419.6818, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  705 value =  tensor(-419.6432, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  706 value =  tensor(-419.7182, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  707 value =  tensor(-419.8479, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  708 value =  tensor(-419.8674, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  709 value =  tensor(-419.9097, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  710 value =  tensor(-419.7551, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  711 value =  tensor(-419.8087, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  712 value =  tensor(-419.7213, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  713 value =  tensor(-419.6687, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  714 value =  tensor(-419.7825, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  715 value =  tensor(-419.7527, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  716 value =  tensor(-419.7730, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  717 value =  tensor(-419.8783, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  718 value =  tensor(-420.0019, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  719 value =  tensor(-419.8078, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  720 value =  tensor(-419.8164, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  721 value =  tensor(-419.8739, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  722 value =  tensor(-419.8875, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  723 value =  tensor(-419.7483, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  724 value =  tensor(-419.7544, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  725 value =  tensor(-419.7161, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  726 value =  tensor(-419.8090, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  727 value =  tensor(-419.8487, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  728 value =  tensor(-419.8140, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  729 value =  tensor(-419.8553, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  730 value =  tensor(-419.7465, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  731 value =  tensor(-419.8668, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  732 value =  tensor(-419.8123, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  733 value =  tensor(-419.7321, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  734 value =  tensor(-419.4750, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  735 value =  tensor(-419.6619, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  736 value =  tensor(-419.6225, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  737 value =  tensor(-419.7287, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  738 value =  tensor(-419.6414, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  739 value =  tensor(-419.6422, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  740 value =  tensor(-419.7554, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  741 value =  tensor(-419.7816, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  742 value =  tensor(-419.6759, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  743 value =  tensor(-419.6926, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  744 value =  tensor(-419.7219, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  745 value =  tensor(-419.6412, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  746 value =  tensor(-419.6201, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  747 value =  tensor(-419.6760, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  748 value =  tensor(-419.7423, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  749 value =  tensor(-419.6458, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  750 value =  tensor(-419.7230, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  751 value =  tensor(-419.8839, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  752 value =  tensor(-419.6791, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  753 value =  tensor(-419.6635, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  754 value =  tensor(-419.7408, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  755 value =  tensor(-419.7347, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  756 value =  tensor(-419.7511, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  757 value =  tensor(-419.7685, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  758 value =  tensor(-419.9370, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  759 value =  tensor(-419.7242, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  760 value =  tensor(-419.7191, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  761 value =  tensor(-419.6418, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  762 value =  tensor(-419.5483, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  763 value =  tensor(-419.7271, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  764 value =  tensor(-419.9582, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  765 value =  tensor(-419.7418, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  766 value =  tensor(-419.6880, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  767 value =  tensor(-419.7908, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  768 value =  tensor(-419.8247, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  769 value =  tensor(-419.9278, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  770 value =  tensor(-419.8506, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  771 value =  tensor(-419.8452, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  772 value =  tensor(-419.8630, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  773 value =  tensor(-419.8053, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  774 value =  tensor(-419.9008, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  775 value =  tensor(-419.8396, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  776 value =  tensor(-419.9211, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  777 value =  tensor(-419.8727, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  778 value =  tensor(-419.8763, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  779 value =  tensor(-419.6895, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  780 value =  tensor(-419.6412, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  781 value =  tensor(-419.8374, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  782 value =  tensor(-419.8678, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  783 value =  tensor(-419.7574, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  784 value =  tensor(-419.7250, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  785 value =  tensor(-419.7502, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  786 value =  tensor(-419.8504, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  787 value =  tensor(-419.6441, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  788 value =  tensor(-419.6649, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  789 value =  tensor(-419.7986, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  790 value =  tensor(-419.8539, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  791 value =  tensor(-419.8052, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  792 value =  tensor(-419.7122, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  793 value =  tensor(-419.6750, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  794 value =  tensor(-419.7165, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  795 value =  tensor(-419.6688, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  796 value =  tensor(-419.7608, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  797 value =  tensor(-419.4692, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  798 value =  tensor(-419.8088, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  799 value =  tensor(-419.8887, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  800 value =  tensor(-419.6318, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  801 value =  tensor(-419.6543, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  802 value =  tensor(-419.6687, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  803 value =  tensor(-419.6719, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  804 value =  tensor(-419.7077, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  805 value =  tensor(-419.5305, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  806 value =  tensor(-419.6552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  807 value =  tensor(-419.8615, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  808 value =  tensor(-419.7754, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  809 value =  tensor(-419.6079, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  810 value =  tensor(-419.5065, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  811 value =  tensor(-419.5516, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  812 value =  tensor(-419.6442, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  813 value =  tensor(-419.7316, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  814 value =  tensor(-419.4107, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  815 value =  tensor(-419.3537, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  816 value =  tensor(-419.4890, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  817 value =  tensor(-419.6395, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  818 value =  tensor(-419.8682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  819 value =  tensor(-419.7896, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  820 value =  tensor(-419.7043, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  821 value =  tensor(-419.6081, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  822 value =  tensor(-419.6495, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  823 value =  tensor(-419.7440, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  824 value =  tensor(-419.7903, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  825 value =  tensor(-419.7479, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  826 value =  tensor(-419.6992, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  827 value =  tensor(-419.7563, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  828 value =  tensor(-419.5848, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  829 value =  tensor(-419.5648, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  830 value =  tensor(-419.6796, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  831 value =  tensor(-419.7339, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  832 value =  tensor(-419.7967, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  833 value =  tensor(-419.6649, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  834 value =  tensor(-419.5757, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  835 value =  tensor(-419.6755, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  836 value =  tensor(-419.9314, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  837 value =  tensor(-419.8187, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  838 value =  tensor(-419.4637, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  839 value =  tensor(-419.7090, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  840 value =  tensor(-419.7499, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  841 value =  tensor(-419.7617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  842 value =  tensor(-419.5876, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  843 value =  tensor(-419.5945, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  844 value =  tensor(-419.7063, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  845 value =  tensor(-419.7272, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  846 value =  tensor(-419.7964, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  847 value =  tensor(-419.6589, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  848 value =  tensor(-419.7139, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  849 value =  tensor(-419.8373, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  850 value =  tensor(-419.7938, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  851 value =  tensor(-419.7860, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  852 value =  tensor(-419.8255, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  853 value =  tensor(-419.8225, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  854 value =  tensor(-419.8610, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  855 value =  tensor(-419.8789, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  856 value =  tensor(-419.8601, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  857 value =  tensor(-419.7929, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  858 value =  tensor(-419.8630, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  859 value =  tensor(-419.8302, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  860 value =  tensor(-419.7527, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  861 value =  tensor(-419.8231, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  862 value =  tensor(-419.6203, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  863 value =  tensor(-419.7710, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  864 value =  tensor(-419.7016, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  865 value =  tensor(-419.6445, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  866 value =  tensor(-419.6980, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  867 value =  tensor(-419.6740, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  868 value =  tensor(-419.7191, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  869 value =  tensor(-419.8340, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  870 value =  tensor(-419.7602, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  871 value =  tensor(-419.6007, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  872 value =  tensor(-419.5518, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  873 value =  tensor(-419.6576, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  874 value =  tensor(-419.8548, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  875 value =  tensor(-419.8123, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  876 value =  tensor(-419.8202, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  877 value =  tensor(-419.8589, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  878 value =  tensor(-419.9375, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  879 value =  tensor(-419.9416, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  880 value =  tensor(-419.9013, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  881 value =  tensor(-419.9045, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  882 value =  tensor(-419.7994, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  883 value =  tensor(-419.8018, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  884 value =  tensor(-419.7753, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  885 value =  tensor(-419.9359, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  886 value =  tensor(-419.9991, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  887 value =  tensor(-419.8617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  888 value =  tensor(-419.8714, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  889 value =  tensor(-419.9195, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  890 value =  tensor(-419.8063, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  891 value =  tensor(-419.7481, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  892 value =  tensor(-419.6609, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  893 value =  tensor(-419.7495, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  894 value =  tensor(-419.9010, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  895 value =  tensor(-419.7756, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  896 value =  tensor(-419.4950, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  897 value =  tensor(-419.4858, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  898 value =  tensor(-419.6266, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  899 value =  tensor(-419.8594, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  900 value =  tensor(-419.7487, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  901 value =  tensor(-419.5676, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  902 value =  tensor(-419.7085, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  903 value =  tensor(-419.7980, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  904 value =  tensor(-419.8162, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  905 value =  tensor(-419.8546, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  906 value =  tensor(-419.8315, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  907 value =  tensor(-419.8230, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  908 value =  tensor(-419.6865, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  909 value =  tensor(-419.7516, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  910 value =  tensor(-419.8077, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  911 value =  tensor(-419.6192, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  912 value =  tensor(-419.6825, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  913 value =  tensor(-419.8505, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  914 value =  tensor(-419.8589, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  915 value =  tensor(-419.6818, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  916 value =  tensor(-419.6461, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  917 value =  tensor(-419.8055, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  918 value =  tensor(-420.0128, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  919 value =  tensor(-419.8107, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  920 value =  tensor(-419.6464, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  921 value =  tensor(-419.6071, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  922 value =  tensor(-419.6524, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  923 value =  tensor(-419.7849, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  924 value =  tensor(-419.7915, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  925 value =  tensor(-419.7321, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  926 value =  tensor(-419.6370, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  927 value =  tensor(-419.7173, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  928 value =  tensor(-419.5892, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  929 value =  tensor(-419.5729, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  930 value =  tensor(-419.8157, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  931 value =  tensor(-419.7827, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  932 value =  tensor(-419.5973, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  933 value =  tensor(-419.7266, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  934 value =  tensor(-419.7403, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  935 value =  tensor(-419.8293, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  936 value =  tensor(-419.8445, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  937 value =  tensor(-419.7564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  938 value =  tensor(-419.5962, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  939 value =  tensor(-419.6511, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  940 value =  tensor(-419.7892, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  941 value =  tensor(-419.9473, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  942 value =  tensor(-419.9119, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  943 value =  tensor(-419.9066, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  944 value =  tensor(-419.9300, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  945 value =  tensor(-419.8991, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  946 value =  tensor(-419.7300, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  947 value =  tensor(-419.7021, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  948 value =  tensor(-419.8505, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  949 value =  tensor(-419.8545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  950 value =  tensor(-419.8137, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  951 value =  tensor(-419.9008, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  952 value =  tensor(-419.7731, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  953 value =  tensor(-419.6472, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  954 value =  tensor(-419.8354, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  955 value =  tensor(-419.9106, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  956 value =  tensor(-419.7271, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  957 value =  tensor(-419.6184, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  958 value =  tensor(-419.6755, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  959 value =  tensor(-419.7147, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  960 value =  tensor(-419.9186, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  961 value =  tensor(-419.6791, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  962 value =  tensor(-419.3960, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  963 value =  tensor(-419.6291, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  964 value =  tensor(-419.7874, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  965 value =  tensor(-419.7088, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  966 value =  tensor(-419.6715, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  967 value =  tensor(-419.6667, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  968 value =  tensor(-419.8686, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  969 value =  tensor(-419.7893, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  970 value =  tensor(-419.6212, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  971 value =  tensor(-419.6907, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  972 value =  tensor(-419.7431, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  973 value =  tensor(-419.6729, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  974 value =  tensor(-419.6406, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  975 value =  tensor(-419.6077, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  976 value =  tensor(-419.5626, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  977 value =  tensor(-419.7084, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  978 value =  tensor(-419.7573, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  979 value =  tensor(-419.6544, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  980 value =  tensor(-419.6722, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  981 value =  tensor(-419.7305, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  982 value =  tensor(-419.7585, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  983 value =  tensor(-419.8701, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  984 value =  tensor(-419.7715, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  985 value =  tensor(-419.8760, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  986 value =  tensor(-419.8853, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  987 value =  tensor(-419.8666, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  988 value =  tensor(-419.9236, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  989 value =  tensor(-419.9785, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  990 value =  tensor(-419.8849, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  991 value =  tensor(-419.8155, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  992 value =  tensor(-419.9568, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  993 value =  tensor(-419.9213, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  994 value =  tensor(-419.8196, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  995 value =  tensor(-419.8227, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  996 value =  tensor(-419.8977, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  997 value =  tensor(-419.8540, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  998 value =  tensor(-419.6500, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  999 value =  tensor(-419.5842, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1000 value =  tensor(-419.9131, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1001 value =  tensor(-419.8682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1002 value =  tensor(-419.6919, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1003 value =  tensor(-419.7430, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1004 value =  tensor(-419.6236, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1005 value =  tensor(-419.6127, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1006 value =  tensor(-419.7997, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1007 value =  tensor(-419.8299, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1008 value =  tensor(-419.7965, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1009 value =  tensor(-419.6282, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1010 value =  tensor(-419.6945, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1011 value =  tensor(-419.8759, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1012 value =  tensor(-419.7635, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1013 value =  tensor(-419.6844, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1014 value =  tensor(-419.5965, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1015 value =  tensor(-419.6419, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1016 value =  tensor(-419.8106, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1017 value =  tensor(-419.9188, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1018 value =  tensor(-419.7898, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1019 value =  tensor(-419.6900, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1020 value =  tensor(-419.7238, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1021 value =  tensor(-419.8694, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1022 value =  tensor(-419.7078, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1023 value =  tensor(-419.6152, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1024 value =  tensor(-419.6349, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1025 value =  tensor(-419.8650, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1026 value =  tensor(-419.7953, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1027 value =  tensor(-419.7105, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1028 value =  tensor(-419.6207, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1029 value =  tensor(-419.6528, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1030 value =  tensor(-419.8156, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1031 value =  tensor(-419.7176, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1032 value =  tensor(-419.8446, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1033 value =  tensor(-419.7465, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1034 value =  tensor(-419.6696, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1035 value =  tensor(-419.6902, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1036 value =  tensor(-419.6343, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1037 value =  tensor(-419.6393, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1038 value =  tensor(-419.8286, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1039 value =  tensor(-420.0341, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1040 value =  tensor(-419.5511, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1041 value =  tensor(-419.4799, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1042 value =  tensor(-419.6638, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1043 value =  tensor(-419.5659, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1044 value =  tensor(-419.5908, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1045 value =  tensor(-419.4926, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1046 value =  tensor(-419.4419, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1047 value =  tensor(-419.7062, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1048 value =  tensor(-419.6959, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1049 value =  tensor(-419.6229, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1050 value =  tensor(-419.6637, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1051 value =  tensor(-419.7062, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1052 value =  tensor(-419.6325, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1053 value =  tensor(-419.5031, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1054 value =  tensor(-419.5789, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1055 value =  tensor(-419.7595, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1056 value =  tensor(-419.8418, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1057 value =  tensor(-419.8255, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1058 value =  tensor(-419.7500, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1059 value =  tensor(-419.8147, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1060 value =  tensor(-419.7492, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1061 value =  tensor(-419.7433, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1062 value =  tensor(-419.7574, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1063 value =  tensor(-419.8643, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1064 value =  tensor(-419.7522, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1065 value =  tensor(-419.6951, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1066 value =  tensor(-419.6338, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1067 value =  tensor(-419.7739, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1068 value =  tensor(-419.8892, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1069 value =  tensor(-419.6448, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1070 value =  tensor(-419.6332, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1071 value =  tensor(-419.7862, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1072 value =  tensor(-419.7964, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1073 value =  tensor(-419.5623, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1074 value =  tensor(-419.5081, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1075 value =  tensor(-419.5896, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1076 value =  tensor(-419.6961, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1077 value =  tensor(-419.7364, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1078 value =  tensor(-419.8194, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1079 value =  tensor(-419.7570, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1080 value =  tensor(-419.6192, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1081 value =  tensor(-419.7664, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1082 value =  tensor(-420.0009, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1083 value =  tensor(-419.8945, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1084 value =  tensor(-419.8336, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1085 value =  tensor(-419.8638, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1086 value =  tensor(-419.8979, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1087 value =  tensor(-419.9360, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1088 value =  tensor(-420.0266, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1089 value =  tensor(-419.9661, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1090 value =  tensor(-419.7564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1091 value =  tensor(-419.7731, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1092 value =  tensor(-419.6550, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1093 value =  tensor(-419.7513, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1094 value =  tensor(-419.7702, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1095 value =  tensor(-419.6395, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1096 value =  tensor(-419.7556, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1097 value =  tensor(-419.8571, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1098 value =  tensor(-419.9068, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1099 value =  tensor(-419.8055, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1100 value =  tensor(-419.7007, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1101 value =  tensor(-419.6535, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1102 value =  tensor(-419.7743, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1103 value =  tensor(-419.9910, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1104 value =  tensor(-419.8929, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1105 value =  tensor(-419.8062, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1106 value =  tensor(-419.8224, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1107 value =  tensor(-419.7366, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1108 value =  tensor(-419.7593, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1109 value =  tensor(-419.9603, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1110 value =  tensor(-419.9836, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1111 value =  tensor(-419.8896, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1112 value =  tensor(-419.8760, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1113 value =  tensor(-419.8160, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1114 value =  tensor(-419.8774, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1115 value =  tensor(-419.9786, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1116 value =  tensor(-419.9083, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1117 value =  tensor(-419.7350, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1118 value =  tensor(-419.7227, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1119 value =  tensor(-419.8517, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1120 value =  tensor(-419.9368, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1121 value =  tensor(-419.7757, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1122 value =  tensor(-419.8058, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1123 value =  tensor(-419.8147, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1124 value =  tensor(-419.9374, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1125 value =  tensor(-419.9246, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1126 value =  tensor(-419.7853, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1127 value =  tensor(-419.7869, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1128 value =  tensor(-419.7898, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1129 value =  tensor(-419.7943, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1130 value =  tensor(-419.8997, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1131 value =  tensor(-419.6764, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1132 value =  tensor(-419.6729, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1133 value =  tensor(-419.7130, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1134 value =  tensor(-419.8962, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1135 value =  tensor(-419.7529, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1136 value =  tensor(-419.5973, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1137 value =  tensor(-419.5639, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1138 value =  tensor(-419.6903, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1139 value =  tensor(-419.8152, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1140 value =  tensor(-419.7558, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1141 value =  tensor(-419.5766, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1142 value =  tensor(-419.4573, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1143 value =  tensor(-419.5861, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1144 value =  tensor(-419.7659, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1145 value =  tensor(-419.5798, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1146 value =  tensor(-419.5595, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1147 value =  tensor(-419.7062, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1148 value =  tensor(-419.7703, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1149 value =  tensor(-419.6717, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1150 value =  tensor(-419.6372, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1151 value =  tensor(-419.4941, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1152 value =  tensor(-419.5807, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1153 value =  tensor(-419.7258, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1154 value =  tensor(-419.7278, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1155 value =  tensor(-419.7398, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1156 value =  tensor(-419.7585, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1157 value =  tensor(-419.7146, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1158 value =  tensor(-419.7024, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1159 value =  tensor(-419.7299, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1160 value =  tensor(-419.8662, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1161 value =  tensor(-419.8423, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1162 value =  tensor(-419.7941, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1163 value =  tensor(-419.7528, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1164 value =  tensor(-419.8535, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1165 value =  tensor(-419.7012, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1166 value =  tensor(-419.7186, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1167 value =  tensor(-419.8287, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1168 value =  tensor(-419.7428, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1169 value =  tensor(-419.7089, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1170 value =  tensor(-419.6298, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1171 value =  tensor(-419.6552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1172 value =  tensor(-419.7883, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1173 value =  tensor(-419.9382, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1174 value =  tensor(-420.0370, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1175 value =  tensor(-419.8278, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1176 value =  tensor(-419.8199, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1177 value =  tensor(-419.8425, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1178 value =  tensor(-419.8012, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1179 value =  tensor(-419.7814, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1180 value =  tensor(-419.7385, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1181 value =  tensor(-419.8899, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1182 value =  tensor(-420.0259, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1183 value =  tensor(-419.9272, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1184 value =  tensor(-419.8668, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1185 value =  tensor(-419.9602, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1186 value =  tensor(-419.7710, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1187 value =  tensor(-419.7999, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1188 value =  tensor(-419.8835, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1189 value =  tensor(-419.9366, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1190 value =  tensor(-419.9451, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1191 value =  tensor(-419.9455, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1192 value =  tensor(-419.9569, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1193 value =  tensor(-419.9232, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1194 value =  tensor(-420.0055, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1195 value =  tensor(-419.9051, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1196 value =  tensor(-419.8240, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1197 value =  tensor(-419.7632, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1198 value =  tensor(-419.7906, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1199 value =  tensor(-419.8197, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1200 value =  tensor(-419.7803, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1201 value =  tensor(-419.6898, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1202 value =  tensor(-419.8438, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1203 value =  tensor(-419.9346, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1204 value =  tensor(-419.8168, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1205 value =  tensor(-419.7825, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1206 value =  tensor(-419.9562, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1207 value =  tensor(-419.9001, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1208 value =  tensor(-419.9320, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1209 value =  tensor(-419.8634, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1210 value =  tensor(-419.7564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1211 value =  tensor(-419.7070, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1212 value =  tensor(-419.7198, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1213 value =  tensor(-419.8364, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1214 value =  tensor(-419.9409, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1215 value =  tensor(-419.7905, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1216 value =  tensor(-419.7842, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1217 value =  tensor(-419.7635, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1218 value =  tensor(-419.6943, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1219 value =  tensor(-419.7669, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1220 value =  tensor(-419.9536, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1221 value =  tensor(-419.7034, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1222 value =  tensor(-419.5390, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1223 value =  tensor(-419.6091, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1224 value =  tensor(-419.6886, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1225 value =  tensor(-419.7988, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1226 value =  tensor(-419.8200, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1227 value =  tensor(-419.8103, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1228 value =  tensor(-419.5425, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1229 value =  tensor(-419.4321, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1230 value =  tensor(-419.5684, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1231 value =  tensor(-419.7078, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1232 value =  tensor(-419.7343, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1233 value =  tensor(-419.7191, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1234 value =  tensor(-419.7960, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1235 value =  tensor(-419.9551, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1236 value =  tensor(-419.8651, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1237 value =  tensor(-419.8875, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1238 value =  tensor(-419.8867, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1239 value =  tensor(-419.7011, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1240 value =  tensor(-420.0218, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1241 value =  tensor(-419.7543, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1242 value =  tensor(-419.5606, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1243 value =  tensor(-419.6962, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1244 value =  tensor(-419.7592, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1245 value =  tensor(-419.7690, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1246 value =  tensor(-419.7162, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1247 value =  tensor(-419.6839, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1248 value =  tensor(-419.7539, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1249 value =  tensor(-419.8617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1250 value =  tensor(-419.8802, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1251 value =  tensor(-419.6805, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1252 value =  tensor(-419.6296, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1253 value =  tensor(-419.7428, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1254 value =  tensor(-419.9125, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1255 value =  tensor(-419.9134, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1256 value =  tensor(-419.8296, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1257 value =  tensor(-419.8716, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1258 value =  tensor(-419.8451, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1259 value =  tensor(-419.8818, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1260 value =  tensor(-419.9252, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1261 value =  tensor(-420.0659, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1262 value =  tensor(-419.8887, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1263 value =  tensor(-419.8664, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1264 value =  tensor(-420.0013, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1265 value =  tensor(-419.8823, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1266 value =  tensor(-419.7908, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1267 value =  tensor(-419.8023, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1268 value =  tensor(-419.8782, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1269 value =  tensor(-420.0106, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1270 value =  tensor(-419.9772, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1271 value =  tensor(-419.9861, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1272 value =  tensor(-419.9096, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1273 value =  tensor(-419.9635, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1274 value =  tensor(-419.9210, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1275 value =  tensor(-419.9621, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1276 value =  tensor(-420.0673, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1277 value =  tensor(-419.9921, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1278 value =  tensor(-419.8843, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1279 value =  tensor(-419.9535, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1280 value =  tensor(-419.9483, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1281 value =  tensor(-419.9521, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1282 value =  tensor(-419.9695, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1283 value =  tensor(-420.0085, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1284 value =  tensor(-420.0084, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1285 value =  tensor(-419.8802, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1286 value =  tensor(-419.9539, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1287 value =  tensor(-419.9926, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1288 value =  tensor(-419.9957, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1289 value =  tensor(-420.0622, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1290 value =  tensor(-419.9375, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1291 value =  tensor(-419.9686, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1292 value =  tensor(-419.8437, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1293 value =  tensor(-419.8800, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1294 value =  tensor(-419.9819, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1295 value =  tensor(-419.8963, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1296 value =  tensor(-419.9971, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1297 value =  tensor(-419.8865, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1298 value =  tensor(-419.9230, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1299 value =  tensor(-419.9165, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1300 value =  tensor(-420.0631, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1301 value =  tensor(-420.0048, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1302 value =  tensor(-420.0168, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1303 value =  tensor(-420.0617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1304 value =  tensor(-419.9330, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1305 value =  tensor(-420.0590, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1306 value =  tensor(-419.9215, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1307 value =  tensor(-419.7243, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1308 value =  tensor(-419.8345, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1309 value =  tensor(-419.9073, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1310 value =  tensor(-420.0318, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1311 value =  tensor(-419.7947, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1312 value =  tensor(-419.8742, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1313 value =  tensor(-419.9966, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1314 value =  tensor(-419.9284, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1315 value =  tensor(-419.7599, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1316 value =  tensor(-419.9276, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1317 value =  tensor(-420.0654, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1318 value =  tensor(-419.9211, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1319 value =  tensor(-419.8149, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1320 value =  tensor(-419.8889, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1321 value =  tensor(-419.9542, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1322 value =  tensor(-420.0225, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1323 value =  tensor(-419.9449, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1324 value =  tensor(-419.9261, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1325 value =  tensor(-419.8106, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1326 value =  tensor(-419.8378, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1327 value =  tensor(-419.9278, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1328 value =  tensor(-419.8942, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1329 value =  tensor(-419.9502, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1330 value =  tensor(-419.8641, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1331 value =  tensor(-419.8071, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1332 value =  tensor(-419.8433, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1333 value =  tensor(-419.7162, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1334 value =  tensor(-419.6693, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1335 value =  tensor(-419.7852, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1336 value =  tensor(-419.9152, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1337 value =  tensor(-419.7004, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1338 value =  tensor(-419.6708, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1339 value =  tensor(-419.6963, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1340 value =  tensor(-419.6411, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1341 value =  tensor(-419.9089, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1342 value =  tensor(-419.8404, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1343 value =  tensor(-419.8189, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1344 value =  tensor(-419.7554, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1345 value =  tensor(-419.7745, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1346 value =  tensor(-419.8441, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1347 value =  tensor(-419.9024, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1348 value =  tensor(-419.9617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1349 value =  tensor(-419.8189, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1350 value =  tensor(-419.7996, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1351 value =  tensor(-419.7872, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1352 value =  tensor(-419.8830, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1353 value =  tensor(-420.0255, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1354 value =  tensor(-419.7880, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1355 value =  tensor(-419.7468, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1356 value =  tensor(-419.9249, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1357 value =  tensor(-419.9302, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1358 value =  tensor(-419.7871, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1359 value =  tensor(-419.8713, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1360 value =  tensor(-420.0448, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1361 value =  tensor(-419.9602, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1362 value =  tensor(-419.8165, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1363 value =  tensor(-419.9226, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1364 value =  tensor(-419.9190, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1365 value =  tensor(-419.9719, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1366 value =  tensor(-419.8240, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1367 value =  tensor(-419.7561, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1368 value =  tensor(-419.9182, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1369 value =  tensor(-419.8600, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1370 value =  tensor(-419.8582, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1371 value =  tensor(-419.8640, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1372 value =  tensor(-419.9498, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1373 value =  tensor(-419.8879, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1374 value =  tensor(-419.8876, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1375 value =  tensor(-419.8557, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1376 value =  tensor(-419.8787, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1377 value =  tensor(-420.0224, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1378 value =  tensor(-419.9918, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1379 value =  tensor(-419.9004, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1380 value =  tensor(-420.0665, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1381 value =  tensor(-419.8586, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1382 value =  tensor(-419.7818, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1383 value =  tensor(-419.8596, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1384 value =  tensor(-419.7084, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1385 value =  tensor(-419.7354, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1386 value =  tensor(-419.7434, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1387 value =  tensor(-419.9125, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1388 value =  tensor(-420.0254, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1389 value =  tensor(-419.7132, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1390 value =  tensor(-419.6616, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1391 value =  tensor(-419.9176, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1392 value =  tensor(-419.8790, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1393 value =  tensor(-419.9006, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1394 value =  tensor(-419.8029, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1395 value =  tensor(-419.9039, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1396 value =  tensor(-419.7354, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1397 value =  tensor(-419.6155, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1398 value =  tensor(-419.7356, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1399 value =  tensor(-419.9415, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1400 value =  tensor(-419.9126, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1401 value =  tensor(-419.8016, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1402 value =  tensor(-419.6360, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1403 value =  tensor(-419.6919, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1404 value =  tensor(-419.7619, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1405 value =  tensor(-419.7828, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1406 value =  tensor(-419.9337, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1407 value =  tensor(-419.8197, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1408 value =  tensor(-419.7632, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1409 value =  tensor(-419.7234, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1410 value =  tensor(-419.8331, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1411 value =  tensor(-419.9581, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1412 value =  tensor(-419.8218, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1413 value =  tensor(-419.8064, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1414 value =  tensor(-419.9170, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1415 value =  tensor(-419.7782, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1416 value =  tensor(-419.7953, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1417 value =  tensor(-419.9066, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1418 value =  tensor(-419.8586, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1419 value =  tensor(-419.6213, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1420 value =  tensor(-419.7686, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1421 value =  tensor(-419.7186, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1422 value =  tensor(-419.6738, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1423 value =  tensor(-419.8497, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1424 value =  tensor(-419.7797, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1425 value =  tensor(-419.6688, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1426 value =  tensor(-419.7439, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1427 value =  tensor(-419.7682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1428 value =  tensor(-419.9485, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1429 value =  tensor(-419.8636, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1430 value =  tensor(-419.7675, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1431 value =  tensor(-419.9097, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1432 value =  tensor(-419.8451, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1433 value =  tensor(-419.8533, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1434 value =  tensor(-420.0219, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1435 value =  tensor(-419.8735, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1436 value =  tensor(-419.8019, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1437 value =  tensor(-419.7838, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1438 value =  tensor(-419.8927, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1439 value =  tensor(-419.8073, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1440 value =  tensor(-419.8453, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1441 value =  tensor(-419.8364, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1442 value =  tensor(-419.7968, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1443 value =  tensor(-419.8878, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1444 value =  tensor(-419.8829, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1445 value =  tensor(-419.8843, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1446 value =  tensor(-419.6655, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1447 value =  tensor(-419.7639, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1448 value =  tensor(-419.8156, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1449 value =  tensor(-419.8366, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1450 value =  tensor(-419.9949, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1451 value =  tensor(-419.8232, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1452 value =  tensor(-419.7128, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1453 value =  tensor(-419.6976, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1454 value =  tensor(-419.7686, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1455 value =  tensor(-419.8297, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1456 value =  tensor(-419.9415, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1457 value =  tensor(-419.9094, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1458 value =  tensor(-419.8750, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1459 value =  tensor(-419.9576, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1460 value =  tensor(-419.9840, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1461 value =  tensor(-419.8955, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1462 value =  tensor(-419.8726, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1463 value =  tensor(-419.8338, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1464 value =  tensor(-419.7661, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1465 value =  tensor(-419.8116, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1466 value =  tensor(-419.8416, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1467 value =  tensor(-419.8714, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1468 value =  tensor(-419.8739, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1469 value =  tensor(-419.7854, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1470 value =  tensor(-419.7079, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1471 value =  tensor(-419.7457, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1472 value =  tensor(-419.7951, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1473 value =  tensor(-419.9424, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1474 value =  tensor(-419.7305, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1475 value =  tensor(-419.6612, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1476 value =  tensor(-419.7485, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1477 value =  tensor(-419.6849, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1478 value =  tensor(-419.7766, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1479 value =  tensor(-419.9657, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1480 value =  tensor(-419.7397, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1481 value =  tensor(-419.7218, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1482 value =  tensor(-419.8773, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1483 value =  tensor(-419.9354, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1484 value =  tensor(-419.9716, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1485 value =  tensor(-419.9786, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1486 value =  tensor(-420.0224, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1487 value =  tensor(-419.9988, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1488 value =  tensor(-419.9222, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1489 value =  tensor(-419.8787, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1490 value =  tensor(-419.9155, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1491 value =  tensor(-419.8779, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1492 value =  tensor(-419.9158, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1493 value =  tensor(-419.9202, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1494 value =  tensor(-419.9363, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1495 value =  tensor(-419.9704, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1496 value =  tensor(-419.8210, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1497 value =  tensor(-419.8066, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1498 value =  tensor(-419.7682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1499 value =  tensor(-419.9295, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1500 value =  tensor(-419.8438, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1501 value =  tensor(-419.7542, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1502 value =  tensor(-419.7339, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1503 value =  tensor(-419.7947, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1504 value =  tensor(-419.9937, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1505 value =  tensor(-419.8441, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1506 value =  tensor(-419.8591, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1507 value =  tensor(-419.8380, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1508 value =  tensor(-419.9465, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1509 value =  tensor(-419.9043, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1510 value =  tensor(-419.9020, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1511 value =  tensor(-419.7657, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1512 value =  tensor(-419.8152, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1513 value =  tensor(-419.9496, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1514 value =  tensor(-419.9653, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1515 value =  tensor(-419.8961, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1516 value =  tensor(-419.7632, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1517 value =  tensor(-419.9314, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1518 value =  tensor(-420.0400, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1519 value =  tensor(-419.9460, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1520 value =  tensor(-419.9380, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1521 value =  tensor(-419.9903, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1522 value =  tensor(-419.9565, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1523 value =  tensor(-420.0504, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1524 value =  tensor(-419.9344, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1525 value =  tensor(-419.9288, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1526 value =  tensor(-419.8497, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1527 value =  tensor(-419.8723, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1528 value =  tensor(-420.0318, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1529 value =  tensor(-419.9847, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1530 value =  tensor(-419.9533, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1531 value =  tensor(-419.9200, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1532 value =  tensor(-419.8144, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1533 value =  tensor(-419.7600, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1534 value =  tensor(-419.8831, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1535 value =  tensor(-419.9367, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1536 value =  tensor(-419.9299, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1537 value =  tensor(-419.9990, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1538 value =  tensor(-419.9707, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1539 value =  tensor(-419.9359, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1540 value =  tensor(-420.0038, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1541 value =  tensor(-419.9818, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1542 value =  tensor(-419.8769, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1543 value =  tensor(-419.8016, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1544 value =  tensor(-419.8564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1545 value =  tensor(-420.0700, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1546 value =  tensor(-419.8643, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1547 value =  tensor(-419.8435, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1548 value =  tensor(-419.8977, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1549 value =  tensor(-419.8305, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1550 value =  tensor(-419.9571, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1551 value =  tensor(-420.0809, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1552 value =  tensor(-419.9251, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1553 value =  tensor(-420.0086, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1554 value =  tensor(-419.9611, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1555 value =  tensor(-419.9855, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1556 value =  tensor(-419.8752, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1557 value =  tensor(-419.7874, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1558 value =  tensor(-419.8954, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1559 value =  tensor(-419.9829, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1560 value =  tensor(-419.8933, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1561 value =  tensor(-419.8478, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1562 value =  tensor(-419.8598, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1563 value =  tensor(-419.9795, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1564 value =  tensor(-419.7949, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1565 value =  tensor(-419.8754, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1566 value =  tensor(-419.8825, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1567 value =  tensor(-419.9708, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1568 value =  tensor(-419.9443, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1569 value =  tensor(-419.8145, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1570 value =  tensor(-419.7303, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1571 value =  tensor(-419.7903, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1572 value =  tensor(-419.9316, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1573 value =  tensor(-419.8727, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1574 value =  tensor(-419.9777, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1575 value =  tensor(-419.9375, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1576 value =  tensor(-419.9095, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1577 value =  tensor(-419.9513, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1578 value =  tensor(-419.7256, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1579 value =  tensor(-419.7263, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1580 value =  tensor(-419.8788, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1581 value =  tensor(-419.9161, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1582 value =  tensor(-419.7255, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1583 value =  tensor(-419.7208, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1584 value =  tensor(-419.8170, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1585 value =  tensor(-419.7576, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1586 value =  tensor(-419.5671, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1587 value =  tensor(-419.5844, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1588 value =  tensor(-419.7558, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1589 value =  tensor(-419.7679, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1590 value =  tensor(-419.7655, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1591 value =  tensor(-419.8347, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1592 value =  tensor(-419.7869, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1593 value =  tensor(-419.7646, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1594 value =  tensor(-419.7028, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1595 value =  tensor(-419.8205, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1596 value =  tensor(-419.6778, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1597 value =  tensor(-419.7748, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1598 value =  tensor(-419.8322, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1599 value =  tensor(-419.6820, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1600 value =  tensor(-419.6682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1601 value =  tensor(-419.6704, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1602 value =  tensor(-419.8892, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1603 value =  tensor(-419.8671, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1604 value =  tensor(-419.5150, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1605 value =  tensor(-419.7940, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1606 value =  tensor(-419.9102, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1607 value =  tensor(-419.7143, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1608 value =  tensor(-419.7083, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1609 value =  tensor(-419.7199, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1610 value =  tensor(-419.7829, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1611 value =  tensor(-419.8670, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1612 value =  tensor(-419.8213, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1613 value =  tensor(-419.7592, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1614 value =  tensor(-419.9080, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1615 value =  tensor(-419.9659, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1616 value =  tensor(-419.7018, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1617 value =  tensor(-419.5998, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1618 value =  tensor(-419.6980, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1619 value =  tensor(-419.7453, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1620 value =  tensor(-419.8545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1621 value =  tensor(-420.0327, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1622 value =  tensor(-419.5561, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1623 value =  tensor(-419.6692, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1624 value =  tensor(-420.0052, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1625 value =  tensor(-419.8952, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1626 value =  tensor(-419.8635, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1627 value =  tensor(-419.9431, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1628 value =  tensor(-419.9393, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1629 value =  tensor(-419.9361, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1630 value =  tensor(-419.9450, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1631 value =  tensor(-419.9383, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1632 value =  tensor(-419.9885, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1633 value =  tensor(-419.9028, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1634 value =  tensor(-419.9201, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1635 value =  tensor(-419.9158, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1636 value =  tensor(-419.8935, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1637 value =  tensor(-419.8823, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1638 value =  tensor(-419.8391, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1639 value =  tensor(-419.8896, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1640 value =  tensor(-419.9222, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1641 value =  tensor(-419.8692, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1642 value =  tensor(-419.8624, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1643 value =  tensor(-420.0459, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1644 value =  tensor(-420.0238, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1645 value =  tensor(-419.9592, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1646 value =  tensor(-420.1031, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1647 value =  tensor(-419.9808, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1648 value =  tensor(-419.9954, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1649 value =  tensor(-419.9708, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1650 value =  tensor(-419.9647, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1651 value =  tensor(-419.9246, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1652 value =  tensor(-419.8748, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1653 value =  tensor(-420.0175, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1654 value =  tensor(-419.8497, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1655 value =  tensor(-419.7813, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1656 value =  tensor(-419.7991, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1657 value =  tensor(-419.6599, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1658 value =  tensor(-419.8552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1659 value =  tensor(-420.0215, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1660 value =  tensor(-419.8640, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1661 value =  tensor(-419.6708, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1662 value =  tensor(-419.6809, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1663 value =  tensor(-419.9012, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1664 value =  tensor(-419.8270, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1665 value =  tensor(-419.8976, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1666 value =  tensor(-419.8679, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1667 value =  tensor(-419.8223, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1668 value =  tensor(-419.7859, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1669 value =  tensor(-419.8794, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1670 value =  tensor(-419.7976, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1671 value =  tensor(-419.7793, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1672 value =  tensor(-419.9439, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1673 value =  tensor(-419.8372, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1674 value =  tensor(-419.9071, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1675 value =  tensor(-419.9399, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1676 value =  tensor(-419.8225, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1677 value =  tensor(-419.8151, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1678 value =  tensor(-419.8210, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1679 value =  tensor(-419.8213, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1680 value =  tensor(-419.9547, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1681 value =  tensor(-419.8490, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1682 value =  tensor(-419.6946, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1683 value =  tensor(-419.6972, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1684 value =  tensor(-419.6436, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1685 value =  tensor(-419.7409, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1686 value =  tensor(-419.9312, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1687 value =  tensor(-419.7605, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1688 value =  tensor(-419.6542, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1689 value =  tensor(-419.7697, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1690 value =  tensor(-419.9136, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1691 value =  tensor(-419.7867, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1692 value =  tensor(-419.7163, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1693 value =  tensor(-419.9357, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1694 value =  tensor(-419.6878, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1695 value =  tensor(-419.7961, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1696 value =  tensor(-419.8738, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1697 value =  tensor(-419.8859, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1698 value =  tensor(-419.8478, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1699 value =  tensor(-419.7439, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1700 value =  tensor(-419.7124, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1701 value =  tensor(-419.7995, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1702 value =  tensor(-419.8226, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1703 value =  tensor(-419.9301, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1704 value =  tensor(-419.8191, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1705 value =  tensor(-419.7273, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1706 value =  tensor(-419.8854, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1707 value =  tensor(-419.8606, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1708 value =  tensor(-419.7363, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1709 value =  tensor(-419.7908, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1710 value =  tensor(-419.8741, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1711 value =  tensor(-419.9372, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1712 value =  tensor(-419.7643, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1713 value =  tensor(-419.7361, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1714 value =  tensor(-419.8065, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1715 value =  tensor(-419.8553, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1716 value =  tensor(-419.7810, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1717 value =  tensor(-419.7611, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1718 value =  tensor(-419.8947, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1719 value =  tensor(-419.9583, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1720 value =  tensor(-419.9027, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1721 value =  tensor(-419.8600, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1722 value =  tensor(-419.8612, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1723 value =  tensor(-419.9593, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1724 value =  tensor(-419.9449, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1725 value =  tensor(-419.9262, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1726 value =  tensor(-419.9617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1727 value =  tensor(-419.9711, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1728 value =  tensor(-419.9851, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1729 value =  tensor(-419.9961, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1730 value =  tensor(-419.9433, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1731 value =  tensor(-419.9027, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1732 value =  tensor(-420.0360, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1733 value =  tensor(-419.9526, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1734 value =  tensor(-419.9846, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1735 value =  tensor(-420.1122, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1736 value =  tensor(-419.9211, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1737 value =  tensor(-419.8293, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1738 value =  tensor(-419.7549, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1739 value =  tensor(-419.8761, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1740 value =  tensor(-419.9291, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1741 value =  tensor(-419.9186, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1742 value =  tensor(-419.9954, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1743 value =  tensor(-420.0291, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1744 value =  tensor(-419.9004, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1745 value =  tensor(-419.8663, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1746 value =  tensor(-419.9555, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1747 value =  tensor(-420.0016, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1748 value =  tensor(-419.9641, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1749 value =  tensor(-420.0732, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1750 value =  tensor(-419.8357, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1751 value =  tensor(-419.8726, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1752 value =  tensor(-419.9571, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1753 value =  tensor(-419.8408, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1754 value =  tensor(-419.8022, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1755 value =  tensor(-419.6559, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1756 value =  tensor(-419.9120, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1757 value =  tensor(-419.8728, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1758 value =  tensor(-419.6166, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1759 value =  tensor(-419.4666, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1760 value =  tensor(-419.5457, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1761 value =  tensor(-419.7438, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1762 value =  tensor(-419.9348, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1763 value =  tensor(-419.8509, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1764 value =  tensor(-419.7032, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1765 value =  tensor(-419.6693, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1766 value =  tensor(-419.7310, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1767 value =  tensor(-419.6439, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1768 value =  tensor(-419.6299, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1769 value =  tensor(-419.7692, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1770 value =  tensor(-419.9002, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1771 value =  tensor(-419.7901, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1772 value =  tensor(-419.8167, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1773 value =  tensor(-419.8581, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1774 value =  tensor(-419.8263, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1775 value =  tensor(-419.9315, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1776 value =  tensor(-419.9265, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1777 value =  tensor(-419.6036, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1778 value =  tensor(-419.7725, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1779 value =  tensor(-419.6354, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1780 value =  tensor(-419.5932, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1781 value =  tensor(-419.7546, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1782 value =  tensor(-419.7177, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1783 value =  tensor(-419.3869, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1784 value =  tensor(-419.5256, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1785 value =  tensor(-419.7473, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1786 value =  tensor(-419.6838, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1787 value =  tensor(-419.5106, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1788 value =  tensor(-419.5193, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1789 value =  tensor(-419.5015, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1790 value =  tensor(-419.5574, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1791 value =  tensor(-419.6182, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1792 value =  tensor(-419.7873, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1793 value =  tensor(-419.6404, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1794 value =  tensor(-419.6885, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1795 value =  tensor(-419.6302, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1796 value =  tensor(-419.5235, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1797 value =  tensor(-419.5241, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1798 value =  tensor(-419.5571, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1799 value =  tensor(-419.6758, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1800 value =  tensor(-419.8817, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1801 value =  tensor(-419.9019, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1802 value =  tensor(-419.6896, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1803 value =  tensor(-419.6202, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1804 value =  tensor(-419.7640, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1805 value =  tensor(-419.8745, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1806 value =  tensor(-419.9748, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1807 value =  tensor(-419.8364, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1808 value =  tensor(-419.8055, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1809 value =  tensor(-419.8955, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1810 value =  tensor(-419.9119, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1811 value =  tensor(-419.8515, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1812 value =  tensor(-419.8263, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1813 value =  tensor(-419.9441, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1814 value =  tensor(-419.9470, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1815 value =  tensor(-419.8512, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1816 value =  tensor(-419.7900, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1817 value =  tensor(-419.7768, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1818 value =  tensor(-419.8330, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1819 value =  tensor(-419.9138, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1820 value =  tensor(-419.9633, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1821 value =  tensor(-419.8722, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1822 value =  tensor(-419.8285, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1823 value =  tensor(-419.8520, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1824 value =  tensor(-419.9170, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1825 value =  tensor(-419.8925, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1826 value =  tensor(-419.9959, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1827 value =  tensor(-419.8760, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1828 value =  tensor(-420.0391, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1829 value =  tensor(-419.8817, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1830 value =  tensor(-419.8589, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1831 value =  tensor(-419.9338, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1832 value =  tensor(-419.7731, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1833 value =  tensor(-419.8105, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1834 value =  tensor(-419.8796, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1835 value =  tensor(-419.9749, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1836 value =  tensor(-419.9540, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1837 value =  tensor(-419.9130, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1838 value =  tensor(-419.9545, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1839 value =  tensor(-419.9559, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1840 value =  tensor(-419.7981, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1841 value =  tensor(-419.8026, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1842 value =  tensor(-419.8168, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1843 value =  tensor(-419.8780, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1844 value =  tensor(-419.8238, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1845 value =  tensor(-419.7240, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1846 value =  tensor(-419.7677, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1847 value =  tensor(-419.7358, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1848 value =  tensor(-419.7912, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1849 value =  tensor(-419.7039, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1850 value =  tensor(-419.7383, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1851 value =  tensor(-419.7714, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1852 value =  tensor(-419.7943, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1853 value =  tensor(-419.8102, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1854 value =  tensor(-419.8220, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1855 value =  tensor(-419.8550, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1856 value =  tensor(-419.8848, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1857 value =  tensor(-419.9272, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1858 value =  tensor(-419.8548, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1859 value =  tensor(-419.9263, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1860 value =  tensor(-419.9096, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1861 value =  tensor(-419.9701, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1862 value =  tensor(-419.8911, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1863 value =  tensor(-419.8483, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1864 value =  tensor(-420.0030, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1865 value =  tensor(-419.9813, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1866 value =  tensor(-419.9066, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1867 value =  tensor(-419.8227, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1868 value =  tensor(-419.8979, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1869 value =  tensor(-420.0239, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1870 value =  tensor(-419.9272, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1871 value =  tensor(-419.8026, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1872 value =  tensor(-419.9070, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1873 value =  tensor(-419.8666, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1874 value =  tensor(-419.9489, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1875 value =  tensor(-419.8817, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1876 value =  tensor(-419.7513, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1877 value =  tensor(-419.5674, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1878 value =  tensor(-419.6808, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1879 value =  tensor(-419.9131, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1880 value =  tensor(-419.9360, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1881 value =  tensor(-419.7792, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1882 value =  tensor(-419.7857, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1883 value =  tensor(-419.7678, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1884 value =  tensor(-419.7986, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1885 value =  tensor(-419.6872, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1886 value =  tensor(-419.9337, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1887 value =  tensor(-419.9754, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1888 value =  tensor(-419.8987, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1889 value =  tensor(-419.8836, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1890 value =  tensor(-419.9560, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1891 value =  tensor(-419.9996, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1892 value =  tensor(-419.8968, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1893 value =  tensor(-419.9140, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1894 value =  tensor(-419.7567, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1895 value =  tensor(-419.8731, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1896 value =  tensor(-419.8779, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1897 value =  tensor(-419.7424, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1898 value =  tensor(-419.6767, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1899 value =  tensor(-419.8358, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1900 value =  tensor(-419.7357, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1901 value =  tensor(-419.8596, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1902 value =  tensor(-419.9767, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1903 value =  tensor(-419.8074, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1904 value =  tensor(-419.7463, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1905 value =  tensor(-419.8039, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1906 value =  tensor(-419.7960, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1907 value =  tensor(-419.7663, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1908 value =  tensor(-419.8936, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1909 value =  tensor(-419.9005, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1910 value =  tensor(-419.7094, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1911 value =  tensor(-419.5649, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1912 value =  tensor(-419.6824, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1913 value =  tensor(-419.7682, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1914 value =  tensor(-419.8373, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1915 value =  tensor(-419.8842, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1916 value =  tensor(-419.8215, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1917 value =  tensor(-419.8337, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1918 value =  tensor(-419.8663, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1919 value =  tensor(-419.9056, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1920 value =  tensor(-420.1253, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1921 value =  tensor(-419.8212, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1922 value =  tensor(-419.7025, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1923 value =  tensor(-419.7728, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1924 value =  tensor(-419.8894, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1925 value =  tensor(-419.9281, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1926 value =  tensor(-419.9618, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1927 value =  tensor(-419.8564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1928 value =  tensor(-419.8875, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1929 value =  tensor(-420.0073, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1930 value =  tensor(-419.9753, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1931 value =  tensor(-420.0327, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1932 value =  tensor(-419.9820, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1933 value =  tensor(-419.9290, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1934 value =  tensor(-419.7709, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1935 value =  tensor(-419.8152, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1936 value =  tensor(-419.7928, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1937 value =  tensor(-419.8814, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1938 value =  tensor(-419.7951, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1939 value =  tensor(-419.7367, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1940 value =  tensor(-419.6887, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1941 value =  tensor(-419.6530, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1942 value =  tensor(-419.7946, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1943 value =  tensor(-419.7646, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1944 value =  tensor(-419.6270, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1945 value =  tensor(-419.5618, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1946 value =  tensor(-419.5051, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1947 value =  tensor(-419.6182, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1948 value =  tensor(-419.6658, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1949 value =  tensor(-419.9145, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1950 value =  tensor(-419.7822, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1951 value =  tensor(-419.7233, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1952 value =  tensor(-419.7039, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1953 value =  tensor(-419.7978, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1954 value =  tensor(-419.8110, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1955 value =  tensor(-419.8132, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1956 value =  tensor(-419.8721, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1957 value =  tensor(-419.8820, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1958 value =  tensor(-419.9783, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1959 value =  tensor(-420.0267, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1960 value =  tensor(-419.8802, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1961 value =  tensor(-419.9388, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1962 value =  tensor(-419.9557, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1963 value =  tensor(-419.8899, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1964 value =  tensor(-419.8983, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1965 value =  tensor(-419.8699, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1966 value =  tensor(-420.0365, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1967 value =  tensor(-419.9650, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1968 value =  tensor(-419.8986, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1969 value =  tensor(-419.8981, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1970 value =  tensor(-420.0543, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1971 value =  tensor(-419.8916, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1972 value =  tensor(-419.8784, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1973 value =  tensor(-419.9109, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1974 value =  tensor(-419.8517, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1975 value =  tensor(-419.9115, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1976 value =  tensor(-419.8462, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1977 value =  tensor(-419.8578, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1978 value =  tensor(-419.9337, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1979 value =  tensor(-419.9321, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1980 value =  tensor(-419.9769, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1981 value =  tensor(-419.9552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1982 value =  tensor(-419.9004, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1983 value =  tensor(-419.9617, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1984 value =  tensor(-419.8694, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1985 value =  tensor(-420.0552, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1986 value =  tensor(-419.9915, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1987 value =  tensor(-419.9526, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1988 value =  tensor(-419.8933, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1989 value =  tensor(-419.9485, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1990 value =  tensor(-419.7889, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1991 value =  tensor(-419.8564, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1992 value =  tensor(-419.9238, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1993 value =  tensor(-420.0202, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1994 value =  tensor(-419.7370, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1995 value =  tensor(-419.5923, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1996 value =  tensor(-419.6958, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1997 value =  tensor(-419.8408, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1998 value =  tensor(-419.9760, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n",
      "training_step =  1999 value =  tensor(-419.8830, grad_fn=<DotBackward0>)  ; desired value set for optimization =  [-1250.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## generate graph weights\n",
    "NN_graph_params = datalessNN_graph_params(G)\n",
    "\n",
    "graph_order = len(G.nodes)\n",
    "\n",
    "NN = datalessNN(\n",
    "    NN_graph_params[\"theta_tensor\"],\n",
    "    NN_graph_params[\"layer_2_weights\"],\n",
    "    NN_graph_params[\"layer_2_biases\"],\n",
    "    NN_graph_params[\"layer_3_weights\"])\n",
    "\n",
    "################# optimization\n",
    "# good and fast results on most is found at initial_learning_rate = 0.001\n",
    "initial_learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(NN.parameters(), lr=initial_learning_rate)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "theta_constraint = ZeroOneClamp()\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "batch_size_gen = 1\n",
    "batch_size_2 = batch_size_gen\n",
    "\n",
    "################################################################\n",
    "##### X_train is the same for both gen and combined models #####\n",
    "################################################################\n",
    "\n",
    "X_train = np.ones(len(NN_graph_params[\"theta_tensor\"]))\n",
    "\n",
    "############################################################\n",
    "### Y_train_combined is the v_d (desired value)\n",
    "################################################################\n",
    "\n",
    "P_desired = np.zeros(1)\n",
    "P_desired[0] = -graph_order**2 / 2\n",
    "\n",
    "Y_train_combined = np.zeros(shape=(batch_size_2, 1, 1))\n",
    "\n",
    "Y_val_combined = P_desired.reshape(1, 1)\n",
    "for i in range(batch_size_2):\n",
    "    Y_train_combined[i, :, :] = Y_val_combined\n",
    "\n",
    "Y_train_combined = Y_train_combined.reshape(batch_size_2, 1)\n",
    "\n",
    "Y_desired = torch.Tensor(Y_val_combined)\n",
    "Y_val_combined = Y_val_combined.reshape(1, 1, 1)\n",
    "Y_val_combined = Y_val_combined.reshape(1, 1)\n",
    "# Y_val_combined = Y_val_combined.reshape(3)\n",
    "\n",
    "################################################################\n",
    "### train\n",
    "################################################################\n",
    "\n",
    "training_steps = 2000\n",
    "X_star = None\n",
    "\n",
    "start = time.time()\n",
    "for i in range(training_steps):\n",
    "    predicted_y = NN(X_train)\n",
    "\n",
    "    loss = loss_fn(predicted_y, Y_desired)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ## normalize theta values between 0 and 1\n",
    "    NN[0].apply(theta_constraint)\n",
    "\n",
    "    X_star = NN[0].weight\n",
    "\n",
    "    if any(X_star > 1.0) or any(X_star < 0.0):\n",
    "        print(\n",
    "            \"exit AT training step = \",\n",
    "            i,\n",
    "            \"; THERE IS A A VALUE IN THE WEIGHTS OUTSIDE [0,1]\",\n",
    "            X_star\n",
    "        )\n",
    "        break\n",
    "\n",
    "    # check MAXIMAL-IS multiple thresholds !!!\n",
    "    # MAXIMAL_IS_tester = [\n",
    "    #     MAXIMAL_IS_checker(X_star, G, 0.3),\n",
    "    #     MAXIMAL_IS_checker(X_star, G, 0.4),\n",
    "    #     MAXIMAL_IS_checker(X_star, G, 0.5),\n",
    "    #     MAXIMAL_IS_checker(X_star, G, 0.6),\n",
    "    #     MAXIMAL_IS_checker(X_star, G, 0.7),\n",
    "    # ]\n",
    "\n",
    "    # if MAXIMAL_IS_checker(X_star, G, 0.5) == 1:\n",
    "    #     X_star_thresholded_IS = np.zeros(shape=(n_inputss))\n",
    "    #     for ii in range(n_inputss):\n",
    "    #         if X_star[ii] > 0.5:\n",
    "    #             X_star_thresholded_IS[ii] = 1\n",
    "    #     length_IS = np.count_nonzero(X_star_thresholded_IS)\n",
    "    #     # length_IS_w_Imp = np.count_nonzero(\n",
    "    #     #     X_star_thresholded_IS\n",
    "    #     # ) + solution_improve_alg(\n",
    "    #     #     X_star_thresholded_IS, G, np.count_nonzero(X_star_thresholded_IS)\n",
    "    #     # )\n",
    "    #     print(\n",
    "    #         \"IS is found at step \",\n",
    "    #         [i],\n",
    "    #         \"with size = \",\n",
    "    #         length_IS,\n",
    "    #         # \"total with improvement = \",\n",
    "    #         # length_IS_w_Imp,\n",
    "    #     )\n",
    "\n",
    "    # ## exit if we already have a Maximal-IS\n",
    "    # if any(np.array(MAXIMAL_IS_tester) == 1):\n",
    "    #     winning_threshold_temp = np.argmax(np.array(MAXIMAL_IS_tester))\n",
    "    #     winning_threshold = [0.3, 0.4, 0.5, 0.6, 0.7][winning_threshold_temp]\n",
    "    #     end = time.time()\n",
    "    #     X_star_thresholded = np.zeros(shape=(n_inputss))\n",
    "    #     # X_MIN_VALUE_TEST   = np.zeros(shape=(n_inputss))\n",
    "    #     for ii in range(n_inputss):\n",
    "    #         if X_star[ii] > winning_threshold:\n",
    "    #             X_star_thresholded[ii] = 1\n",
    "    #     length = np.count_nonzero(X_star_thresholded) #+ solution_improve_alg(\n",
    "    #     #     X_star_thresholded, G, np.count_nonzero(X_star_thresholded)\n",
    "    #     # )\n",
    "\n",
    "    #     print(\n",
    "    #         \"MAXIMAL-IS IS FOUND AT training step = \",\n",
    "    #         i,\n",
    "    #         \"; Cardinality Ours = \",\n",
    "    #         [length],\n",
    "    #     )\n",
    "    #     # if length >= some_value_if_known:\n",
    "    #     Solution_pool_length.append(length)\n",
    "    #     break\n",
    "\n",
    "    print(\n",
    "        \"training_step = \",\n",
    "        i,\n",
    "        \"value = \",\n",
    "        predicted_y,\n",
    "        \" ; desired value set for optimization = \",\n",
    "        P_desired,\n",
    "    )\n",
    "\n",
    "\n",
    "nx.draw_networkx(G, node_color=X_star.detach().numpy(), pos=nx.shell_layout(G))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
